{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = 'CREMA-D/AudioWAV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':    \n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Crema_df\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "path = np.array(data_path.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>happy</td>\n",
       "      <td>CREMA-D/AudioWAV/1090_TAI_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>angry</td>\n",
       "      <td>CREMA-D/AudioWAV/1061_IOM_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITS_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1055_MTI_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>happy</td>\n",
       "      <td>CREMA-D/AudioWAV/1087_IEO_HAP_LO.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotions                                  Path\n",
       "0        fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1     disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2     disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3         sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4     neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav\n",
       "...       ...                                   ...\n",
       "7437    happy  CREMA-D/AudioWAV/1090_TAI_HAP_XX.wav\n",
       "7438    angry  CREMA-D/AudioWAV/1061_IOM_ANG_XX.wav\n",
       "7439  disgust  CREMA-D/AudioWAV/1067_ITS_DIS_XX.wav\n",
       "7440     fear  CREMA-D/AudioWAV/1055_MTI_FEA_XX.wav\n",
       "7441    happy  CREMA-D/AudioWAV/1087_IEO_HAP_LO.wav\n",
       "\n",
       "[7442 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70196/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_70196/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/home/prat/.local/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(data_path.Path, data_path.Emotions):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22326, 22326, (7442,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.637844</td>\n",
       "      <td>0.606111</td>\n",
       "      <td>0.571997</td>\n",
       "      <td>0.630106</td>\n",
       "      <td>0.714430</td>\n",
       "      <td>0.675026</td>\n",
       "      <td>0.665222</td>\n",
       "      <td>0.719204</td>\n",
       "      <td>0.826163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242615e-10</td>\n",
       "      <td>2.971604e-10</td>\n",
       "      <td>2.766176e-10</td>\n",
       "      <td>2.603836e-10</td>\n",
       "      <td>2.475797e-10</td>\n",
       "      <td>2.377858e-10</td>\n",
       "      <td>2.303247e-10</td>\n",
       "      <td>2.252069e-10</td>\n",
       "      <td>2.220143e-10</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054719</td>\n",
       "      <td>0.648945</td>\n",
       "      <td>0.618575</td>\n",
       "      <td>0.585555</td>\n",
       "      <td>0.643181</td>\n",
       "      <td>0.723304</td>\n",
       "      <td>0.677569</td>\n",
       "      <td>0.665227</td>\n",
       "      <td>0.717826</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>...</td>\n",
       "      <td>2.597903e-06</td>\n",
       "      <td>2.547018e-06</td>\n",
       "      <td>2.722617e-06</td>\n",
       "      <td>2.717672e-06</td>\n",
       "      <td>2.615127e-06</td>\n",
       "      <td>2.598697e-06</td>\n",
       "      <td>2.703754e-06</td>\n",
       "      <td>2.725612e-06</td>\n",
       "      <td>2.528838e-06</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059451</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.640867</td>\n",
       "      <td>0.584112</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.634756</td>\n",
       "      <td>0.718933</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>0.665793</td>\n",
       "      <td>0.731998</td>\n",
       "      <td>...</td>\n",
       "      <td>1.885746e-10</td>\n",
       "      <td>1.724273e-10</td>\n",
       "      <td>1.642871e-10</td>\n",
       "      <td>1.507513e-10</td>\n",
       "      <td>1.506967e-10</td>\n",
       "      <td>1.413461e-10</td>\n",
       "      <td>1.223686e-10</td>\n",
       "      <td>1.028102e-10</td>\n",
       "      <td>9.267615e-11</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059764</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.392475</td>\n",
       "      <td>0.459169</td>\n",
       "      <td>0.471746</td>\n",
       "      <td>0.485209</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.797795</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.943509e-08</td>\n",
       "      <td>3.484132e-08</td>\n",
       "      <td>3.144174e-08</td>\n",
       "      <td>2.883970e-08</td>\n",
       "      <td>2.684491e-08</td>\n",
       "      <td>2.534668e-08</td>\n",
       "      <td>2.423224e-08</td>\n",
       "      <td>2.347231e-08</td>\n",
       "      <td>2.300906e-08</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.141958</td>\n",
       "      <td>0.533265</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>0.597065</td>\n",
       "      <td>0.602417</td>\n",
       "      <td>0.612960</td>\n",
       "      <td>0.629087</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.794806</td>\n",
       "      <td>0.695523</td>\n",
       "      <td>...</td>\n",
       "      <td>8.666924e-04</td>\n",
       "      <td>8.913741e-04</td>\n",
       "      <td>8.474859e-04</td>\n",
       "      <td>8.858735e-04</td>\n",
       "      <td>8.761011e-04</td>\n",
       "      <td>8.360007e-04</td>\n",
       "      <td>9.038528e-04</td>\n",
       "      <td>8.289524e-04</td>\n",
       "      <td>7.953483e-04</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.053580  0.637844  0.606111  0.571997  0.630106  0.714430  0.675026   \n",
       "1  0.054719  0.648945  0.618575  0.585555  0.643181  0.723304  0.677569   \n",
       "2  0.059451  0.583235  0.640867  0.584112  0.567250  0.634756  0.718933   \n",
       "3  0.059764  0.452337  0.392475  0.459169  0.471746  0.485209  0.507530   \n",
       "4  0.141958  0.533265  0.539109  0.597065  0.602417  0.612960  0.629087   \n",
       "\n",
       "          7         8         9  ...           153           154  \\\n",
       "0  0.665222  0.719204  0.826163  ...  3.242615e-10  2.971604e-10   \n",
       "1  0.665227  0.717826  0.825301  ...  2.597903e-06  2.547018e-06   \n",
       "2  0.701798  0.665793  0.731998  ...  1.885746e-10  1.724273e-10   \n",
       "3  0.684371  0.797795  0.724068  ...  3.943509e-08  3.484132e-08   \n",
       "4  0.760494  0.794806  0.695523  ...  8.666924e-04  8.913741e-04   \n",
       "\n",
       "            155           156           157           158           159  \\\n",
       "0  2.766176e-10  2.603836e-10  2.475797e-10  2.377858e-10  2.303247e-10   \n",
       "1  2.722617e-06  2.717672e-06  2.615127e-06  2.598697e-06  2.703754e-06   \n",
       "2  1.642871e-10  1.507513e-10  1.506967e-10  1.413461e-10  1.223686e-10   \n",
       "3  3.144174e-08  2.883970e-08  2.684491e-08  2.534668e-08  2.423224e-08   \n",
       "4  8.474859e-04  8.858735e-04  8.761011e-04  8.360007e-04  9.038528e-04   \n",
       "\n",
       "            160           161   labels  \n",
       "0  2.252069e-10  2.220143e-10     fear  \n",
       "1  2.725612e-06  2.528838e-06     fear  \n",
       "2  1.028102e-10  9.267615e-11     fear  \n",
       "3  2.347231e-08  2.300906e-08  disgust  \n",
       "4  8.289524e-04  7.953483e-04  disgust  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162), (16744, 6), (5582, 162), (5582, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162), (16744, 6), (5582, 162), (5582, 6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162, 1), (16744, 6), (5582, 162, 1), (5582, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 23:07:52.282121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 23:07:52.404038: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-06 23:07:52.406236: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:52.406246: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-06 23:07:52.854997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:52.855055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:52.855059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 162, 256)          1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 81, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 81, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 41, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 21, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 11, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 704)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                22560     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557,222\n",
      "Trainable params: 557,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 23:07:54.808715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 23:07:54.808877: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:54.808928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:54.808959: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:54.823785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:54.823833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:54.823871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:07:54.823878: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-06 23:07:54.825149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"import tensorflow as tf\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\nfrom tensorflow.keras.layers import LSTM\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.layers import Dropout\\nmodel = tf.keras.Sequential()\\nmodel.add(LSTM(256, input_shape=(x_train.shape[1], 1), return_sequences=True))\\nmodel.add(Dropout(0.2))\\n\\nmodel.add(LSTM(128, return_sequences=True))\\nmodel.add(Dropout(0.2))\\n\\nmodel.add(LSTM(64))\\nmodel.add(Dropout(0.2))\\n\\nmodel.add(Dense(units=32, activation='relu'))\\nmodel.add(Dropout(0.3))\\n\\nmodel.add(Dense(units=6, activation='softmax'))\\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\n\\nmodel.summary()\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\"\"\"import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(256, input_shape=(x_train.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "262/262 [==============================] - 12s 44ms/step - loss: 1.6133 - accuracy: 0.3080 - val_loss: 1.5552 - val_accuracy: 0.3372 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.5350 - accuracy: 0.3550 - val_loss: 1.5440 - val_accuracy: 0.3452 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "262/262 [==============================] - 13s 51ms/step - loss: 1.5064 - accuracy: 0.3714 - val_loss: 1.4910 - val_accuracy: 0.3681 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "262/262 [==============================] - 16s 62ms/step - loss: 1.4736 - accuracy: 0.3911 - val_loss: 1.4185 - val_accuracy: 0.4104 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "262/262 [==============================] - 14s 54ms/step - loss: 1.4526 - accuracy: 0.4006 - val_loss: 1.4502 - val_accuracy: 0.3895 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "262/262 [==============================] - 16s 62ms/step - loss: 1.4352 - accuracy: 0.4113 - val_loss: 1.4003 - val_accuracy: 0.4196 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 1.4135 - accuracy: 0.4239 - val_loss: 1.3799 - val_accuracy: 0.4350 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 1.3932 - accuracy: 0.4283 - val_loss: 1.3703 - val_accuracy: 0.4326 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.3807 - accuracy: 0.4397 - val_loss: 1.3603 - val_accuracy: 0.4394 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.3637 - accuracy: 0.4437 - val_loss: 1.3447 - val_accuracy: 0.4459 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.3482 - accuracy: 0.4547 - val_loss: 1.3715 - val_accuracy: 0.4378 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.3391 - accuracy: 0.4587 - val_loss: 1.3342 - val_accuracy: 0.4480 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "262/262 [==============================] - 12s 44ms/step - loss: 1.3186 - accuracy: 0.4703 - val_loss: 1.3242 - val_accuracy: 0.4638 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.3116 - accuracy: 0.4664 - val_loss: 1.3225 - val_accuracy: 0.4606 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 1.2936 - accuracy: 0.4789 - val_loss: 1.3130 - val_accuracy: 0.4688 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 1.2810 - accuracy: 0.4830 - val_loss: 1.3208 - val_accuracy: 0.4692 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.2644 - accuracy: 0.4904 - val_loss: 1.2994 - val_accuracy: 0.4731 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.2536 - accuracy: 0.4980 - val_loss: 1.2908 - val_accuracy: 0.4753 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "262/262 [==============================] - 12s 44ms/step - loss: 1.2335 - accuracy: 0.5045 - val_loss: 1.3026 - val_accuracy: 0.4744 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.2245 - accuracy: 0.5090 - val_loss: 1.2890 - val_accuracy: 0.4812 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.2113 - accuracy: 0.5125 - val_loss: 1.2948 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.1873 - accuracy: 0.5220 - val_loss: 1.2864 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "262/262 [==============================] - 11s 44ms/step - loss: 1.1833 - accuracy: 0.5245 - val_loss: 1.2792 - val_accuracy: 0.4799 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.1653 - accuracy: 0.5297 - val_loss: 1.2769 - val_accuracy: 0.4828 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.1457 - accuracy: 0.5396 - val_loss: 1.2759 - val_accuracy: 0.4900 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1320 - accuracy: 0.5469 - val_loss: 1.2828 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1219 - accuracy: 0.5472 - val_loss: 1.2868 - val_accuracy: 0.4821 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1189 - accuracy: 0.5566 - val_loss: 1.2749 - val_accuracy: 0.4900 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.0905 - accuracy: 0.5674 - val_loss: 1.2803 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.0827 - accuracy: 0.5681 - val_loss: 1.2808 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.0598 - accuracy: 0.5790 - val_loss: 1.2865 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.0604 - accuracy: 0.5750 - val_loss: 1.2998 - val_accuracy: 0.4846 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.0452 - accuracy: 0.5826 - val_loss: 1.2890 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.0201 - accuracy: 0.5932 - val_loss: 1.3168 - val_accuracy: 0.4855 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "262/262 [==============================] - 11s 44ms/step - loss: 1.0145 - accuracy: 0.5922 - val_loss: 1.2928 - val_accuracy: 0.4952 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.9878 - accuracy: 0.6066 - val_loss: 1.3068 - val_accuracy: 0.4857 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.9805 - accuracy: 0.6076 - val_loss: 1.3093 - val_accuracy: 0.4869 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.9814 - accuracy: 0.6096 - val_loss: 1.2972 - val_accuracy: 0.5048 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.9551 - accuracy: 0.6209 - val_loss: 1.3365 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.9442 - accuracy: 0.6226 - val_loss: 1.3109 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.9375 - accuracy: 0.6271 - val_loss: 1.3546 - val_accuracy: 0.5004 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.9321 - accuracy: 0.6290 - val_loss: 1.3367 - val_accuracy: 0.4912 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.9014 - accuracy: 0.6395 - val_loss: 1.3388 - val_accuracy: 0.4943 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.9041 - accuracy: 0.6433 - val_loss: 1.3793 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Epoch 45/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8880 - accuracy: 0.6504 - val_loss: 1.3633 - val_accuracy: 0.4971 - lr: 0.0010\n",
      "Epoch 46/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8756 - accuracy: 0.6552 - val_loss: 1.3883 - val_accuracy: 0.4907 - lr: 0.0010\n",
      "Epoch 47/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8669 - accuracy: 0.6530 - val_loss: 1.3571 - val_accuracy: 0.5027 - lr: 0.0010\n",
      "Epoch 48/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8656 - accuracy: 0.6596 - val_loss: 1.3844 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 49/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.8615 - accuracy: 0.6591 - val_loss: 1.3936 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 50/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.8459 - accuracy: 0.6700 - val_loss: 1.4177 - val_accuracy: 0.4966 - lr: 0.0010\n",
      "Epoch 51/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8297 - accuracy: 0.6750 - val_loss: 1.4375 - val_accuracy: 0.4984 - lr: 0.0010\n",
      "Epoch 52/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.8165 - accuracy: 0.6796 - val_loss: 1.4356 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 53/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.7987 - accuracy: 0.6841 - val_loss: 1.4591 - val_accuracy: 0.4957 - lr: 0.0010\n",
      "Epoch 54/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8097 - accuracy: 0.6802 - val_loss: 1.4141 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 55/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.7836 - accuracy: 0.6944 - val_loss: 1.4252 - val_accuracy: 0.4946 - lr: 0.0010\n",
      "Epoch 56/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7880 - accuracy: 0.6890 - val_loss: 1.4972 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 57/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.7783 - accuracy: 0.6943 - val_loss: 1.4974 - val_accuracy: 0.4979 - lr: 0.0010\n",
      "Epoch 58/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7748 - accuracy: 0.6998 - val_loss: 1.4831 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 59/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.7576 - accuracy: 0.7020 - val_loss: 1.5519 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 60/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7578 - accuracy: 0.7041 - val_loss: 1.5203 - val_accuracy: 0.4927 - lr: 0.0010\n",
      "Epoch 61/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7425 - accuracy: 0.7108 - val_loss: 1.4907 - val_accuracy: 0.4996 - lr: 0.0010\n",
      "Epoch 62/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7503 - accuracy: 0.7095 - val_loss: 1.4818 - val_accuracy: 0.4970 - lr: 0.0010\n",
      "Epoch 63/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7301 - accuracy: 0.7149 - val_loss: 1.6191 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 64/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7129 - accuracy: 0.7223 - val_loss: 1.6023 - val_accuracy: 0.5032 - lr: 0.0010\n",
      "Epoch 65/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7163 - accuracy: 0.7164 - val_loss: 1.5242 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 66/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.6946 - accuracy: 0.7299 - val_loss: 1.6025 - val_accuracy: 0.4962 - lr: 0.0010\n",
      "Epoch 67/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.7114 - accuracy: 0.7228 - val_loss: 1.6333 - val_accuracy: 0.4930 - lr: 0.0010\n",
      "Epoch 68/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.6986 - accuracy: 0.7339 - val_loss: 1.6125 - val_accuracy: 0.4986 - lr: 0.0010\n",
      "Epoch 69/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5882 - accuracy: 0.7670 - val_loss: 1.6883 - val_accuracy: 0.5104 - lr: 4.0000e-04\n",
      "Epoch 70/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5577 - accuracy: 0.7792 - val_loss: 1.7464 - val_accuracy: 0.5133 - lr: 4.0000e-04\n",
      "Epoch 71/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5371 - accuracy: 0.7867 - val_loss: 1.7025 - val_accuracy: 0.5143 - lr: 4.0000e-04\n",
      "Epoch 72/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5248 - accuracy: 0.7953 - val_loss: 1.7497 - val_accuracy: 0.5149 - lr: 4.0000e-04\n",
      "Epoch 73/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5212 - accuracy: 0.7958 - val_loss: 1.7209 - val_accuracy: 0.5111 - lr: 4.0000e-04\n",
      "Epoch 74/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5135 - accuracy: 0.8015 - val_loss: 1.7774 - val_accuracy: 0.5109 - lr: 4.0000e-04\n",
      "Epoch 75/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4923 - accuracy: 0.8100 - val_loss: 1.8590 - val_accuracy: 0.5125 - lr: 4.0000e-04\n",
      "Epoch 76/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5087 - accuracy: 0.8014 - val_loss: 1.8285 - val_accuracy: 0.5118 - lr: 4.0000e-04\n",
      "Epoch 77/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4985 - accuracy: 0.8063 - val_loss: 1.8390 - val_accuracy: 0.5133 - lr: 4.0000e-04\n",
      "Epoch 78/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4559 - accuracy: 0.8229 - val_loss: 1.8645 - val_accuracy: 0.5179 - lr: 1.6000e-04\n",
      "Epoch 79/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4396 - accuracy: 0.8299 - val_loss: 1.9286 - val_accuracy: 0.5133 - lr: 1.6000e-04\n",
      "Epoch 80/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4266 - accuracy: 0.8353 - val_loss: 1.9330 - val_accuracy: 0.5165 - lr: 1.6000e-04\n",
      "Epoch 81/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.4362 - accuracy: 0.8300 - val_loss: 1.9323 - val_accuracy: 0.5129 - lr: 1.6000e-04\n",
      "Epoch 82/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4209 - accuracy: 0.8365 - val_loss: 1.9796 - val_accuracy: 0.5159 - lr: 1.6000e-04\n",
      "Epoch 83/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4189 - accuracy: 0.8407 - val_loss: 1.9968 - val_accuracy: 0.5195 - lr: 1.6000e-04\n",
      "Epoch 84/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4186 - accuracy: 0.8377 - val_loss: 1.9892 - val_accuracy: 0.5193 - lr: 1.6000e-04\n",
      "Epoch 85/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4132 - accuracy: 0.8411 - val_loss: 1.9808 - val_accuracy: 0.5150 - lr: 1.6000e-04\n",
      "Epoch 86/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4065 - accuracy: 0.8413 - val_loss: 1.9918 - val_accuracy: 0.5174 - lr: 1.6000e-04\n",
      "Epoch 87/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4057 - accuracy: 0.8444 - val_loss: 2.0306 - val_accuracy: 0.5145 - lr: 1.6000e-04\n",
      "Epoch 88/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4017 - accuracy: 0.8441 - val_loss: 2.0437 - val_accuracy: 0.5158 - lr: 1.6000e-04\n",
      "Epoch 89/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3934 - accuracy: 0.8476 - val_loss: 2.0569 - val_accuracy: 0.5152 - lr: 1.6000e-04\n",
      "Epoch 90/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4002 - accuracy: 0.8452 - val_loss: 2.0548 - val_accuracy: 0.5150 - lr: 1.6000e-04\n",
      "Epoch 91/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3950 - accuracy: 0.8483 - val_loss: 2.0672 - val_accuracy: 0.5124 - lr: 1.6000e-04\n",
      "Epoch 92/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3695 - accuracy: 0.8555 - val_loss: 2.1036 - val_accuracy: 0.5136 - lr: 6.4000e-05\n",
      "Epoch 93/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3743 - accuracy: 0.8564 - val_loss: 2.1055 - val_accuracy: 0.5147 - lr: 6.4000e-05\n",
      "Epoch 94/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3619 - accuracy: 0.8622 - val_loss: 2.1062 - val_accuracy: 0.5136 - lr: 6.4000e-05\n",
      "Epoch 95/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3667 - accuracy: 0.8588 - val_loss: 2.1098 - val_accuracy: 0.5145 - lr: 6.4000e-05\n",
      "Epoch 96/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3704 - accuracy: 0.8573 - val_loss: 2.1435 - val_accuracy: 0.5116 - lr: 6.4000e-05\n",
      "Epoch 97/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3568 - accuracy: 0.8629 - val_loss: 2.1302 - val_accuracy: 0.5118 - lr: 2.5600e-05\n",
      "Epoch 98/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3639 - accuracy: 0.8581 - val_loss: 2.1326 - val_accuracy: 0.5115 - lr: 2.5600e-05\n",
      "Epoch 99/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3515 - accuracy: 0.8640 - val_loss: 2.1453 - val_accuracy: 0.5104 - lr: 2.5600e-05\n",
      "Epoch 100/150\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 0.3545 - accuracy: 0.8647 - val_loss: 2.1407 - val_accuracy: 0.5129 - lr: 2.5600e-05\n",
      "Epoch 101/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3568 - accuracy: 0.8639 - val_loss: 2.1429 - val_accuracy: 0.5133 - lr: 2.5600e-05\n",
      "Epoch 102/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3500 - accuracy: 0.8625 - val_loss: 2.1455 - val_accuracy: 0.5111 - lr: 1.0240e-05\n",
      "Epoch 103/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3461 - accuracy: 0.8650 - val_loss: 2.1491 - val_accuracy: 0.5127 - lr: 1.0240e-05\n",
      "Epoch 104/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3536 - accuracy: 0.8650 - val_loss: 2.1529 - val_accuracy: 0.5120 - lr: 1.0240e-05\n",
      "Epoch 105/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3554 - accuracy: 0.8640 - val_loss: 2.1525 - val_accuracy: 0.5115 - lr: 1.0240e-05\n",
      "Epoch 106/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3497 - accuracy: 0.8661 - val_loss: 2.1543 - val_accuracy: 0.5104 - lr: 4.0960e-06\n",
      "Epoch 107/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3522 - accuracy: 0.8639 - val_loss: 2.1543 - val_accuracy: 0.5116 - lr: 4.0960e-06\n",
      "Epoch 108/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3438 - accuracy: 0.8681 - val_loss: 2.1548 - val_accuracy: 0.5116 - lr: 1.6384e-06\n",
      "Epoch 109/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3484 - accuracy: 0.8664 - val_loss: 2.1547 - val_accuracy: 0.5120 - lr: 1.6384e-06\n",
      "Epoch 110/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3498 - accuracy: 0.8663 - val_loss: 2.1561 - val_accuracy: 0.5120 - lr: 1.6384e-06\n",
      "Epoch 111/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3491 - accuracy: 0.8671 - val_loss: 2.1565 - val_accuracy: 0.5120 - lr: 6.5536e-07\n",
      "Epoch 112/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3412 - accuracy: 0.8718 - val_loss: 2.1571 - val_accuracy: 0.5118 - lr: 6.5536e-07\n",
      "Epoch 113/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3516 - accuracy: 0.8651 - val_loss: 2.1576 - val_accuracy: 0.5118 - lr: 6.5536e-07\n",
      "Epoch 114/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3412 - accuracy: 0.8691 - val_loss: 2.1578 - val_accuracy: 0.5115 - lr: 6.5536e-07\n",
      "Epoch 115/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3496 - accuracy: 0.8668 - val_loss: 2.1577 - val_accuracy: 0.5116 - lr: 2.6214e-07\n",
      "Epoch 116/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3507 - accuracy: 0.8662 - val_loss: 2.1578 - val_accuracy: 0.5116 - lr: 2.6214e-07\n",
      "Epoch 117/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3553 - accuracy: 0.8644 - val_loss: 2.1577 - val_accuracy: 0.5116 - lr: 1.0486e-07\n",
      "Epoch 118/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3445 - accuracy: 0.8690 - val_loss: 2.1578 - val_accuracy: 0.5113 - lr: 1.0486e-07\n",
      "Epoch 119/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3491 - accuracy: 0.8670 - val_loss: 2.1579 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 120/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3480 - accuracy: 0.8648 - val_loss: 2.1578 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 121/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3452 - accuracy: 0.8687 - val_loss: 2.1579 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 122/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3431 - accuracy: 0.8660 - val_loss: 2.1580 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 123/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3495 - accuracy: 0.8675 - val_loss: 2.1580 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 124/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3491 - accuracy: 0.8659 - val_loss: 2.1580 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 125/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3457 - accuracy: 0.8672 - val_loss: 2.1581 - val_accuracy: 0.5111 - lr: 1.0000e-07\n",
      "Epoch 126/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3441 - accuracy: 0.8693 - val_loss: 2.1581 - val_accuracy: 0.5111 - lr: 1.0000e-07\n",
      "Epoch 127/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3486 - accuracy: 0.8666 - val_loss: 2.1581 - val_accuracy: 0.5111 - lr: 1.0000e-07\n",
      "Epoch 128/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3499 - accuracy: 0.8626 - val_loss: 2.1581 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 129/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3507 - accuracy: 0.8665 - val_loss: 2.1581 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 130/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3498 - accuracy: 0.8638 - val_loss: 2.1581 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 131/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3450 - accuracy: 0.8672 - val_loss: 2.1581 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 132/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3537 - accuracy: 0.8641 - val_loss: 2.1581 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 133/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3485 - accuracy: 0.8661 - val_loss: 2.1582 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 134/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3462 - accuracy: 0.8669 - val_loss: 2.1583 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 135/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3490 - accuracy: 0.8682 - val_loss: 2.1583 - val_accuracy: 0.5116 - lr: 1.0000e-07\n",
      "Epoch 136/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3499 - accuracy: 0.8641 - val_loss: 2.1583 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 137/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3504 - accuracy: 0.8667 - val_loss: 2.1584 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 138/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3449 - accuracy: 0.8654 - val_loss: 2.1584 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 139/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3557 - accuracy: 0.8622 - val_loss: 2.1584 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 140/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3480 - accuracy: 0.8665 - val_loss: 2.1583 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 141/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3366 - accuracy: 0.8720 - val_loss: 2.1584 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 142/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3459 - accuracy: 0.8653 - val_loss: 2.1584 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 143/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3475 - accuracy: 0.8665 - val_loss: 2.1584 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 144/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3383 - accuracy: 0.8681 - val_loss: 2.1585 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 145/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3416 - accuracy: 0.8701 - val_loss: 2.1586 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 146/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3415 - accuracy: 0.8694 - val_loss: 2.1586 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 147/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3478 - accuracy: 0.8677 - val_loss: 2.1586 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 148/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3452 - accuracy: 0.8665 - val_loss: 2.1587 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
      "Epoch 149/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3463 - accuracy: 0.8638 - val_loss: 2.1588 - val_accuracy: 0.5115 - lr: 1.0000e-07\n",
      "Epoch 150/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3487 - accuracy: 0.8664 - val_loss: 2.1588 - val_accuracy: 0.5115 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=150, validation_data=(x_test, y_test), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70196/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_70196/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "* recording\n",
      "* done recording\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "* recording\n",
      "* done recording\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "* recording\n",
      "* done recording\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[7.1105357e-09 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]\n",
      " [1.4282307e-25 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "* recording\n",
      "* done recording\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[9.9619460e-01 0.0000000e+00 3.8053473e-03 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]\n",
      " [5.0556429e-25 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]\n",
      " [2.4077317e-05 0.0000000e+00 9.9997592e-01 3.0770352e-27 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "* recording\n",
      "* done recording\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "* recording\n",
      "* done recording\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m wf\u001b[39m.\u001b[39mwriteframes(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(frames))\n\u001b[1;32m     36\u001b[0m wf\u001b[39m.\u001b[39mclose()\n\u001b[0;32m---> 37\u001b[0m audioFile \u001b[39m=\u001b[39m get_features(WAVE_OUTPUT_FILENAME)\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mpredict(audioFile))\n",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m, in \u001b[0;36mget_features\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     37\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((result, res2)) \u001b[39m# stacking vertically\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m# data with stretching and pitching\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m new_data \u001b[39m=\u001b[39m stretch(data)\n\u001b[1;32m     41\u001b[0m data_stretch_pitch \u001b[39m=\u001b[39m pitch(new_data, sample_rate)\n\u001b[1;32m     42\u001b[0m res3 \u001b[39m=\u001b[39m extract_features(data_stretch_pitch)\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mstretch\u001b[0;34m(data, rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstretch\u001b[39m(data, rate\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m librosa\u001b[39m.\u001b[39;49meffects\u001b[39m.\u001b[39;49mtime_stretch(data, rate)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/util/decorators.py:104\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPass \u001b[39m\u001b[39m{\u001b[39;00margs_msg\u001b[39m}\u001b[39;00m\u001b[39m as keyword args. From version \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mversion\u001b[39m}\u001b[39;00m\u001b[39m passing these as positional arguments \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m kwargs\u001b[39m.\u001b[39mupdate(\u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args))\n\u001b[0;32m--> 104\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/effects.py:241\u001b[0m, in \u001b[0;36mtime_stretch\u001b[0;34m(y, rate, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m ParameterError(\u001b[39m\"\u001b[39m\u001b[39mrate must be a positive number\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39m# Construct the short-term Fourier transform (STFT)\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m stft \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mstft(y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    243\u001b[0m \u001b[39m# Stretch by phase vocoding\u001b[39;00m\n\u001b[1;32m    244\u001b[0m stft_stretch \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mphase_vocoder(\n\u001b[1;32m    245\u001b[0m     stft,\n\u001b[1;32m    246\u001b[0m     rate\u001b[39m=\u001b[39mrate,\n\u001b[1;32m    247\u001b[0m     hop_length\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mhop_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    248\u001b[0m     n_fft\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mn_fft\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    249\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:254\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mfor\u001b[39;00m bl_s \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, stft_matrix\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], n_columns):\n\u001b[1;32m    252\u001b[0m     bl_t \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(bl_s \u001b[39m+\u001b[39m n_columns, stft_matrix\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 254\u001b[0m     stft_matrix[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, bl_s:bl_t] \u001b[39m=\u001b[39m fft\u001b[39m.\u001b[39;49mrfft(\n\u001b[1;32m    255\u001b[0m         fft_window \u001b[39m*\u001b[39;49m y_frames[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, bl_s:bl_t], axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m stft_matrix\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mrfft\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/fft/_pocketfft.py:409\u001b[0m, in \u001b[0;36mrfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    407\u001b[0m     n \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mshape[axis]\n\u001b[1;32m    408\u001b[0m inv_norm \u001b[39m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[0;32m--> 409\u001b[0m output \u001b[39m=\u001b[39m _raw_fft(a, n, axis, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, inv_norm)\n\u001b[1;32m    410\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/fft/_pocketfft.py:73\u001b[0m, in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     a \u001b[39m=\u001b[39m swapaxes(a, axis, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     r \u001b[39m=\u001b[39m pfi\u001b[39m.\u001b[39;49mexecute(a, is_real, is_forward, fct)\n\u001b[1;32m     74\u001b[0m     r \u001b[39m=\u001b[39m swapaxes(r, axis, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "while True:\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 2\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"* done recording\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    audioFile = get_features(WAVE_OUTPUT_FILENAME)\n",
    "    print(model.predict(audioFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70196/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_70196/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 6.7680508e-36, 0.0000000e+00, 2.0294972e-12,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [8.0735727e-38, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing = get_features('CREMA-D/AudioWAV/1001_IEO_HAP_HI.wav')\n",
    "model.predict(thing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'angry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pred_test \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m      5\u001b[0m y_pred \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minverse_transform(pred_test)\n\u001b[0;32m----> 7\u001b[0m y_test \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(encoder\u001b[39m.\u001b[39;49minverse_transform(y_test))\n\u001b[1;32m      8\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPredicted Labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mActual Labels\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mPredicted Labels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:926\u001b[0m, in \u001b[0;36mOneHotEncoder.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39mConvert the data back to the original representation.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39m    Inverse transformed array.\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    925\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 926\u001b[0m X \u001b[39m=\u001b[39m check_array(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    928\u001b[0m n_samples, _ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    929\u001b[0m n_features \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories_)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    876\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    879\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    881\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'angry'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "pred_test = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "\n",
    "y_test = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "\"\"\"\n",
    "3=angry\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       fear\n",
       "1    disgust\n",
       "2    disgust\n",
       "3        sad\n",
       "4    neutral\n",
       "Name: Emotions, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crema_df['Emotions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
