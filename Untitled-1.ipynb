{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = 'CREMA-D/AudioWAV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Crema_df\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "path = np.array(data_path.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>happy</td>\n",
       "      <td>CREMA-D/AudioWAV/1090_TAI_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>angry</td>\n",
       "      <td>CREMA-D/AudioWAV/1061_IOM_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITS_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1055_MTI_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>happy</td>\n",
       "      <td>CREMA-D/AudioWAV/1087_IEO_HAP_LO.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotions                                  Path\n",
       "0        fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1     disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2     disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3         sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4     neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav\n",
       "...       ...                                   ...\n",
       "7437    happy  CREMA-D/AudioWAV/1090_TAI_HAP_XX.wav\n",
       "7438    angry  CREMA-D/AudioWAV/1061_IOM_ANG_XX.wav\n",
       "7439  disgust  CREMA-D/AudioWAV/1067_ITS_DIS_XX.wav\n",
       "7440     fear  CREMA-D/AudioWAV/1055_MTI_FEA_XX.wav\n",
       "7441    happy  CREMA-D/AudioWAV/1087_IEO_HAP_LO.wav\n",
       "\n",
       "[7442 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(data_path.Path, data_path.Emotions):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22326, 22326, (7442,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.637844</td>\n",
       "      <td>0.606111</td>\n",
       "      <td>0.571997</td>\n",
       "      <td>0.630106</td>\n",
       "      <td>0.714430</td>\n",
       "      <td>0.675026</td>\n",
       "      <td>0.665222</td>\n",
       "      <td>0.719204</td>\n",
       "      <td>0.826163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242615e-10</td>\n",
       "      <td>2.971604e-10</td>\n",
       "      <td>2.766176e-10</td>\n",
       "      <td>2.603836e-10</td>\n",
       "      <td>2.475797e-10</td>\n",
       "      <td>2.377858e-10</td>\n",
       "      <td>2.303247e-10</td>\n",
       "      <td>2.252069e-10</td>\n",
       "      <td>2.220143e-10</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073369</td>\n",
       "      <td>0.655098</td>\n",
       "      <td>0.699145</td>\n",
       "      <td>0.629233</td>\n",
       "      <td>0.649345</td>\n",
       "      <td>0.738596</td>\n",
       "      <td>0.725968</td>\n",
       "      <td>0.665546</td>\n",
       "      <td>0.675751</td>\n",
       "      <td>0.779170</td>\n",
       "      <td>...</td>\n",
       "      <td>4.500719e-05</td>\n",
       "      <td>4.307814e-05</td>\n",
       "      <td>4.332699e-05</td>\n",
       "      <td>4.328919e-05</td>\n",
       "      <td>4.559321e-05</td>\n",
       "      <td>4.655413e-05</td>\n",
       "      <td>4.166971e-05</td>\n",
       "      <td>4.272920e-05</td>\n",
       "      <td>4.455606e-05</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059451</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.640867</td>\n",
       "      <td>0.584112</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.634756</td>\n",
       "      <td>0.718933</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>0.665793</td>\n",
       "      <td>0.731998</td>\n",
       "      <td>...</td>\n",
       "      <td>1.885746e-10</td>\n",
       "      <td>1.724273e-10</td>\n",
       "      <td>1.642871e-10</td>\n",
       "      <td>1.507513e-10</td>\n",
       "      <td>1.506967e-10</td>\n",
       "      <td>1.413461e-10</td>\n",
       "      <td>1.223686e-10</td>\n",
       "      <td>1.028102e-10</td>\n",
       "      <td>9.267615e-11</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059764</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.392475</td>\n",
       "      <td>0.459169</td>\n",
       "      <td>0.471746</td>\n",
       "      <td>0.485209</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.797795</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.943509e-08</td>\n",
       "      <td>3.484132e-08</td>\n",
       "      <td>3.144174e-08</td>\n",
       "      <td>2.883970e-08</td>\n",
       "      <td>2.684491e-08</td>\n",
       "      <td>2.534668e-08</td>\n",
       "      <td>2.423224e-08</td>\n",
       "      <td>2.347231e-08</td>\n",
       "      <td>2.300906e-08</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133207</td>\n",
       "      <td>0.530112</td>\n",
       "      <td>0.535527</td>\n",
       "      <td>0.597062</td>\n",
       "      <td>0.600960</td>\n",
       "      <td>0.600175</td>\n",
       "      <td>0.614219</td>\n",
       "      <td>0.755441</td>\n",
       "      <td>0.805861</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>...</td>\n",
       "      <td>6.820107e-04</td>\n",
       "      <td>7.106585e-04</td>\n",
       "      <td>6.829731e-04</td>\n",
       "      <td>6.685151e-04</td>\n",
       "      <td>6.235510e-04</td>\n",
       "      <td>6.871602e-04</td>\n",
       "      <td>7.090057e-04</td>\n",
       "      <td>6.874368e-04</td>\n",
       "      <td>6.561742e-04</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.053580  0.637844  0.606111  0.571997  0.630106  0.714430  0.675026   \n",
       "1  0.073369  0.655098  0.699145  0.629233  0.649345  0.738596  0.725968   \n",
       "2  0.059451  0.583235  0.640867  0.584112  0.567250  0.634756  0.718933   \n",
       "3  0.059764  0.452337  0.392475  0.459169  0.471746  0.485209  0.507530   \n",
       "4  0.133207  0.530112  0.535527  0.597062  0.600960  0.600175  0.614219   \n",
       "\n",
       "          7         8         9  ...           153           154  \\\n",
       "0  0.665222  0.719204  0.826163  ...  3.242615e-10  2.971604e-10   \n",
       "1  0.665546  0.675751  0.779170  ...  4.500719e-05  4.307814e-05   \n",
       "2  0.701798  0.665793  0.731998  ...  1.885746e-10  1.724273e-10   \n",
       "3  0.684371  0.797795  0.724068  ...  3.943509e-08  3.484132e-08   \n",
       "4  0.755441  0.805861  0.703650  ...  6.820107e-04  7.106585e-04   \n",
       "\n",
       "            155           156           157           158           159  \\\n",
       "0  2.766176e-10  2.603836e-10  2.475797e-10  2.377858e-10  2.303247e-10   \n",
       "1  4.332699e-05  4.328919e-05  4.559321e-05  4.655413e-05  4.166971e-05   \n",
       "2  1.642871e-10  1.507513e-10  1.506967e-10  1.413461e-10  1.223686e-10   \n",
       "3  3.144174e-08  2.883970e-08  2.684491e-08  2.534668e-08  2.423224e-08   \n",
       "4  6.829731e-04  6.685151e-04  6.235510e-04  6.871602e-04  7.090057e-04   \n",
       "\n",
       "            160           161   labels  \n",
       "0  2.252069e-10  2.220143e-10     fear  \n",
       "1  4.272920e-05  4.455606e-05     fear  \n",
       "2  1.028102e-10  9.267615e-11     fear  \n",
       "3  2.347231e-08  2.300906e-08  disgust  \n",
       "4  6.874368e-04  6.561742e-04  disgust  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162), (16744, 6), (5582, 162), (5582, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162), (16744, 6), (5582, 162), (5582, 6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162, 1), (16744, 6), (5582, 162, 1), (5582, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 162, 256)          1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 81, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 81, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 41, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 21, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 11, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 704)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                22560     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557,222\n",
      "Trainable params: 557,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 22:28:38.980047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-21 22:28:38.980218: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-21 22:28:38.980273: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-21 22:28:38.980301: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-21 22:28:38.991077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-21 22:28:38.991112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-21 22:28:38.991141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-21 22:28:38.991147: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-21 22:28:38.991998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "262/262 [==============================] - 12s 41ms/step - loss: 1.6013 - accuracy: 0.3190 - val_loss: 1.5333 - val_accuracy: 0.3486 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 1.5216 - accuracy: 0.3583 - val_loss: 1.5187 - val_accuracy: 0.3628 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.4828 - accuracy: 0.3815 - val_loss: 1.4427 - val_accuracy: 0.3945 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.4654 - accuracy: 0.3975 - val_loss: 1.4317 - val_accuracy: 0.4004 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 1.4441 - accuracy: 0.4089 - val_loss: 1.3937 - val_accuracy: 0.4210 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.4182 - accuracy: 0.4166 - val_loss: 1.3827 - val_accuracy: 0.4341 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 1.4065 - accuracy: 0.4217 - val_loss: 1.3722 - val_accuracy: 0.4280 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.3927 - accuracy: 0.4296 - val_loss: 1.3622 - val_accuracy: 0.4394 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3777 - accuracy: 0.4371 - val_loss: 1.3595 - val_accuracy: 0.4296 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3624 - accuracy: 0.4450 - val_loss: 1.3429 - val_accuracy: 0.4427 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3525 - accuracy: 0.4471 - val_loss: 1.3568 - val_accuracy: 0.4317 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3428 - accuracy: 0.4551 - val_loss: 1.3387 - val_accuracy: 0.4583 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.3279 - accuracy: 0.4599 - val_loss: 1.3322 - val_accuracy: 0.4502 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.3190 - accuracy: 0.4649 - val_loss: 1.3291 - val_accuracy: 0.4588 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3000 - accuracy: 0.4698 - val_loss: 1.3240 - val_accuracy: 0.4618 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.2907 - accuracy: 0.4751 - val_loss: 1.3256 - val_accuracy: 0.4511 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.2862 - accuracy: 0.4814 - val_loss: 1.2969 - val_accuracy: 0.4638 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.2678 - accuracy: 0.4878 - val_loss: 1.2850 - val_accuracy: 0.4787 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.2486 - accuracy: 0.4910 - val_loss: 1.2827 - val_accuracy: 0.4747 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.2417 - accuracy: 0.4947 - val_loss: 1.2946 - val_accuracy: 0.4747 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "261/262 [============================>.] - ETA: 0s - loss: 1.2317 - accuracy: 0.5018"
     ]
    }
   ],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=150, validation_data=(x_test, y_test), callbacks=[rlrp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
