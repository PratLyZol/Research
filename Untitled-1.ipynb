{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = 'CREMA-D/AudioWAV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-03-01-02-02-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-05-02-02-02-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprise</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-08-02-02-02-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calm</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-02-01-01-01-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-08-01-01-01-02.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotions                                       Path\n",
       "0     happy  RAVDESS/Actor_02/03-01-03-01-02-02-02.wav\n",
       "1     angry  RAVDESS/Actor_02/03-01-05-02-02-02-02.wav\n",
       "2  surprise  RAVDESS/Actor_02/03-01-08-02-02-02-02.wav\n",
       "3      calm  RAVDESS/Actor_02/03-01-02-01-01-01-02.wav\n",
       "4  surprise  RAVDESS/Actor_02/03-01-08-01-01-01-02.wav"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "ravdess_dir = os.listdir('RAVDESS')\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for dir in ravdess_dir:\n",
    "    actor = os.listdir('RAVDESS/' + dir)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append('RAVDESS/' + dir + '/' + file)\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)   \n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':    \n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotions                                               Path\n",
       "0  surprise  archive/tess toronto emotional speech set data...\n",
       "1  surprise  archive/tess toronto emotional speech set data...\n",
       "2  surprise  archive/tess toronto emotional speech set data...\n",
       "3  surprise  archive/tess toronto emotional speech set data...\n",
       "4  surprise  archive/tess toronto emotional speech set data..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tess = 'archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data'\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + '/' + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing = [Crema_df, Ravdess_df, Tess_df]\n",
    "data_path = pd.concat(thing)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "path = np.array(data_path.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return abs(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Emotions                                               Path\n",
       "0         fear               CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1      disgust               CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2      disgust               CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3          sad               CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4      neutral               CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav\n",
       "...        ...                                                ...\n",
       "2795  surprise  archive/tess toronto emotional speech set data...\n",
       "2796  surprise  archive/tess toronto emotional speech set data...\n",
       "2797  surprise  archive/tess toronto emotional speech set data...\n",
       "2798  surprise  archive/tess toronto emotional speech set data...\n",
       "2799  surprise  archive/tess toronto emotional speech set data...\n",
       "\n",
       "[11682 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_32630/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_32630/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "4388it [16:36,  5.02it/s]/home/prat/.local/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n",
      "8882it [34:55,  3.27it/s]/home/prat/.local/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "8882it [34:55,  4.24it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'archive/tess toronto emotional speech set data/TESS Toronto emotional speech set dataYAF_pleasant_surprised/YAF_boat_ps.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/core/audio.py:164\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    167\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/core/audio.py:195\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    197\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/soundfile.py:655\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    654\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    657\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/soundfile.py:1213\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1214\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1215\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'archive/tess toronto emotional speech set data/TESS Toronto emotional speech set dataYAF_pleasant_surprised/YAF_boat_ps.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m path, emotion \u001b[39min\u001b[39;00m tqdm(\u001b[39mzip\u001b[39m(data_path\u001b[39m.\u001b[39mPath, data_path\u001b[39m.\u001b[39mEmotions)):\n\u001b[0;32m----> 4\u001b[0m     feature \u001b[39m=\u001b[39m get_features(path)\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m ele \u001b[39min\u001b[39;00m feature:\n\u001b[1;32m      6\u001b[0m         X\u001b[39m.\u001b[39mappend(ele)\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mget_features\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_features\u001b[39m(path):\n\u001b[1;32m     27\u001b[0m     \u001b[39m# duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     data, sample_rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(path, duration\u001b[39m=\u001b[39;49m\u001b[39m2.5\u001b[39;49m, offset\u001b[39m=\u001b[39;49m\u001b[39m0.6\u001b[39;49m)\n\u001b[1;32m     30\u001b[0m     \u001b[39m# without augmentation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     res1 \u001b[39m=\u001b[39m extract_features(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/core/audio.py:170\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    169\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 170\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/librosa/core/audio.py:226\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    223\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[1;32m    228\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    229\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archive/tess toronto emotional speech set data/TESS Toronto emotional speech set dataYAF_pleasant_surprised/YAF_boat_ps.wav'"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "from tqdm import tqdm\n",
    "for path, emotion in tqdm(zip(data_path.Path, data_path.Emotions)):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26646, 26646, (8882,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.637844</td>\n",
       "      <td>0.606111</td>\n",
       "      <td>0.571997</td>\n",
       "      <td>0.630106</td>\n",
       "      <td>0.714430</td>\n",
       "      <td>0.675026</td>\n",
       "      <td>0.665222</td>\n",
       "      <td>0.719204</td>\n",
       "      <td>0.826163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242615e-10</td>\n",
       "      <td>2.971604e-10</td>\n",
       "      <td>2.766176e-10</td>\n",
       "      <td>2.603836e-10</td>\n",
       "      <td>2.475797e-10</td>\n",
       "      <td>2.377858e-10</td>\n",
       "      <td>2.303247e-10</td>\n",
       "      <td>2.252069e-10</td>\n",
       "      <td>2.220143e-10</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.132957</td>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.726379</td>\n",
       "      <td>0.698947</td>\n",
       "      <td>0.758135</td>\n",
       "      <td>0.814910</td>\n",
       "      <td>0.729029</td>\n",
       "      <td>0.709734</td>\n",
       "      <td>0.757258</td>\n",
       "      <td>0.836447</td>\n",
       "      <td>...</td>\n",
       "      <td>3.205114e-04</td>\n",
       "      <td>3.158077e-04</td>\n",
       "      <td>3.108830e-04</td>\n",
       "      <td>3.203666e-04</td>\n",
       "      <td>3.234957e-04</td>\n",
       "      <td>3.452068e-04</td>\n",
       "      <td>3.267436e-04</td>\n",
       "      <td>3.178039e-04</td>\n",
       "      <td>3.316460e-04</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059451</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.640867</td>\n",
       "      <td>0.584111</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.634756</td>\n",
       "      <td>0.718932</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>0.665793</td>\n",
       "      <td>0.731998</td>\n",
       "      <td>...</td>\n",
       "      <td>1.885746e-10</td>\n",
       "      <td>1.724273e-10</td>\n",
       "      <td>1.642871e-10</td>\n",
       "      <td>1.507513e-10</td>\n",
       "      <td>1.506967e-10</td>\n",
       "      <td>1.413461e-10</td>\n",
       "      <td>1.223686e-10</td>\n",
       "      <td>1.028102e-10</td>\n",
       "      <td>9.267614e-11</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059764</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.392475</td>\n",
       "      <td>0.459169</td>\n",
       "      <td>0.471747</td>\n",
       "      <td>0.485209</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.797795</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.943509e-08</td>\n",
       "      <td>3.484132e-08</td>\n",
       "      <td>3.144174e-08</td>\n",
       "      <td>2.883970e-08</td>\n",
       "      <td>2.684491e-08</td>\n",
       "      <td>2.534668e-08</td>\n",
       "      <td>2.423224e-08</td>\n",
       "      <td>2.347231e-08</td>\n",
       "      <td>2.300906e-08</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089606</td>\n",
       "      <td>0.468121</td>\n",
       "      <td>0.466837</td>\n",
       "      <td>0.531340</td>\n",
       "      <td>0.532640</td>\n",
       "      <td>0.540389</td>\n",
       "      <td>0.577090</td>\n",
       "      <td>0.741766</td>\n",
       "      <td>0.791216</td>\n",
       "      <td>0.679455</td>\n",
       "      <td>...</td>\n",
       "      <td>1.549916e-04</td>\n",
       "      <td>1.723924e-04</td>\n",
       "      <td>1.620936e-04</td>\n",
       "      <td>1.685147e-04</td>\n",
       "      <td>1.714032e-04</td>\n",
       "      <td>1.801680e-04</td>\n",
       "      <td>1.757615e-04</td>\n",
       "      <td>1.691327e-04</td>\n",
       "      <td>1.753686e-04</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.053580  0.637844  0.606111  0.571997  0.630106  0.714430  0.675026   \n",
       "1  0.132957  0.750369  0.726379  0.698947  0.758135  0.814910  0.729029   \n",
       "2  0.059451  0.583235  0.640867  0.584111  0.567250  0.634756  0.718932   \n",
       "3  0.059764  0.452337  0.392475  0.459169  0.471747  0.485209  0.507530   \n",
       "4  0.089606  0.468121  0.466837  0.531340  0.532640  0.540389  0.577090   \n",
       "\n",
       "          7         8         9  ...           153           154  \\\n",
       "0  0.665222  0.719204  0.826163  ...  3.242615e-10  2.971604e-10   \n",
       "1  0.709734  0.757258  0.836447  ...  3.205114e-04  3.158077e-04   \n",
       "2  0.701798  0.665793  0.731998  ...  1.885746e-10  1.724273e-10   \n",
       "3  0.684371  0.797795  0.724068  ...  3.943509e-08  3.484132e-08   \n",
       "4  0.741766  0.791216  0.679455  ...  1.549916e-04  1.723924e-04   \n",
       "\n",
       "            155           156           157           158           159  \\\n",
       "0  2.766176e-10  2.603836e-10  2.475797e-10  2.377858e-10  2.303247e-10   \n",
       "1  3.108830e-04  3.203666e-04  3.234957e-04  3.452068e-04  3.267436e-04   \n",
       "2  1.642871e-10  1.507513e-10  1.506967e-10  1.413461e-10  1.223686e-10   \n",
       "3  3.144174e-08  2.883970e-08  2.684491e-08  2.534668e-08  2.423224e-08   \n",
       "4  1.620936e-04  1.685147e-04  1.714032e-04  1.801680e-04  1.757615e-04   \n",
       "\n",
       "            160           161   labels  \n",
       "0  2.252069e-10  2.220143e-10     fear  \n",
       "1  3.178039e-04  3.316460e-04     fear  \n",
       "2  1.028102e-10  9.267614e-11     fear  \n",
       "3  2.347231e-08  2.300906e-08  disgust  \n",
       "4  1.691327e-04  1.753686e-04  disgust  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15987, 162), (15987, 8), (10659, 162), (10659, 8))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, shuffle=True, test_size=0.4)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15987, 162), (15987, 8), (10659, 162), (10659, 8))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_test = abs(x_test)\n",
    "x_train = abs(x_train)\n",
    "y_train = abs(y_train)\n",
    "y_test = abs(y_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15987, 162, 1), (15987, 8), (10659, 162, 1), (10659, 8))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 23:48:51.386770: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:48:51.386786: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 162, 256)          1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 81, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 81, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 41, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 21, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 11, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 704)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                22560     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557,288\n",
      "Trainable params: 557,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 23:48:53.592053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-06 23:48:53.592243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:48:53.592284: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:48:53.592313: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:48:53.594052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:48:53.594084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:48:53.594111: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:48:53.594117: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-06 23:48:53.594507: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=8, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 1.7689 - accuracy: 0.2843 - val_loss: 2.0350 - val_accuracy: 0.2249 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.6704 - accuracy: 0.3061 - val_loss: 2.0061 - val_accuracy: 0.2387 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.6343 - accuracy: 0.3261 - val_loss: 2.2095 - val_accuracy: 0.2302 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.6183 - accuracy: 0.3267 - val_loss: 2.1528 - val_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.6047 - accuracy: 0.3329 - val_loss: 2.2286 - val_accuracy: 0.2476 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.5799 - accuracy: 0.3447 - val_loss: 2.6295 - val_accuracy: 0.1989 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.5683 - accuracy: 0.3482 - val_loss: 2.4262 - val_accuracy: 0.2440 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.5538 - accuracy: 0.3530 - val_loss: 2.4434 - val_accuracy: 0.2178 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.5374 - accuracy: 0.3629 - val_loss: 2.5475 - val_accuracy: 0.2404 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.5321 - accuracy: 0.3641 - val_loss: 2.5410 - val_accuracy: 0.2247 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.5234 - accuracy: 0.3689 - val_loss: 2.5985 - val_accuracy: 0.2325 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.5026 - accuracy: 0.3729 - val_loss: 2.2671 - val_accuracy: 0.2268 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.4956 - accuracy: 0.3784 - val_loss: 2.6461 - val_accuracy: 0.2210 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.4855 - accuracy: 0.3883 - val_loss: 2.4748 - val_accuracy: 0.2298 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 1.4721 - accuracy: 0.3934 - val_loss: 2.5282 - val_accuracy: 0.2033 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.4555 - accuracy: 0.3954 - val_loss: 2.4698 - val_accuracy: 0.2201 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.4416 - accuracy: 0.4025 - val_loss: 2.4937 - val_accuracy: 0.2416 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.4313 - accuracy: 0.4118 - val_loss: 2.7011 - val_accuracy: 0.2305 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.4183 - accuracy: 0.4137 - val_loss: 2.8407 - val_accuracy: 0.2353 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.4158 - accuracy: 0.4141 - val_loss: 2.6100 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3869 - accuracy: 0.4323 - val_loss: 2.6100 - val_accuracy: 0.2308 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3828 - accuracy: 0.4287 - val_loss: 2.6980 - val_accuracy: 0.2479 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3857 - accuracy: 0.4334 - val_loss: 3.6929 - val_accuracy: 0.2193 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3619 - accuracy: 0.4424 - val_loss: 3.0395 - val_accuracy: 0.2359 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3498 - accuracy: 0.4477 - val_loss: 3.2413 - val_accuracy: 0.2464 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3309 - accuracy: 0.4582 - val_loss: 3.5977 - val_accuracy: 0.2469 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3284 - accuracy: 0.4593 - val_loss: 3.7359 - val_accuracy: 0.2301 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3211 - accuracy: 0.4604 - val_loss: 3.0025 - val_accuracy: 0.2499 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.3003 - accuracy: 0.4651 - val_loss: 3.4462 - val_accuracy: 0.2427 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.2945 - accuracy: 0.4786 - val_loss: 3.8911 - val_accuracy: 0.2366 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 1.2751 - accuracy: 0.4761 - val_loss: 4.0773 - val_accuracy: 0.2535 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.2549 - accuracy: 0.4898 - val_loss: 4.3641 - val_accuracy: 0.2394 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.2614 - accuracy: 0.4860 - val_loss: 4.2562 - val_accuracy: 0.2117 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.2374 - accuracy: 0.4967 - val_loss: 4.6539 - val_accuracy: 0.2074 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.2210 - accuracy: 0.5053 - val_loss: 4.0223 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1956 - accuracy: 0.5187 - val_loss: 4.3486 - val_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1938 - accuracy: 0.5189 - val_loss: 4.2776 - val_accuracy: 0.2212 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1665 - accuracy: 0.5339 - val_loss: 4.4632 - val_accuracy: 0.2228 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1557 - accuracy: 0.5374 - val_loss: 5.4404 - val_accuracy: 0.2572 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1373 - accuracy: 0.5445 - val_loss: 4.7926 - val_accuracy: 0.2513 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1329 - accuracy: 0.5504 - val_loss: 4.9269 - val_accuracy: 0.2357 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1087 - accuracy: 0.5591 - val_loss: 4.5254 - val_accuracy: 0.2364 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.1006 - accuracy: 0.5623 - val_loss: 4.8493 - val_accuracy: 0.2329 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.0827 - accuracy: 0.5706 - val_loss: 5.5346 - val_accuracy: 0.2127 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.0755 - accuracy: 0.5785 - val_loss: 5.6175 - val_accuracy: 0.2196 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.0566 - accuracy: 0.5778 - val_loss: 4.3979 - val_accuracy: 0.2518 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 1.0435 - accuracy: 0.5910 - val_loss: 4.5123 - val_accuracy: 0.2523 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.0443 - accuracy: 0.5869 - val_loss: 4.8299 - val_accuracy: 0.2454 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.0206 - accuracy: 0.5972 - val_loss: 4.3673 - val_accuracy: 0.2425 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 12s 23ms/step - loss: 1.0179 - accuracy: 0.5985 - val_loss: 4.4719 - val_accuracy: 0.2484 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69483/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_69483/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.82705966e-02 6.70785367e-01 6.82891548e-01 7.06805825e-01\n",
      "  6.81205392e-01 6.64030850e-01 6.35018289e-01 5.87556541e-01\n",
      "  5.72615564e-01 6.78701103e-01 7.44292617e-01 8.34446132e-01\n",
      "  7.64888704e-01 3.45326782e+02 1.26157448e+02 2.06477890e+01\n",
      "  4.68509979e+01 2.60175467e+00 1.14741344e+01 2.68084259e+01\n",
      "  9.06569481e-01 5.26198530e+00 8.52141285e+00 1.26096706e+01\n",
      "  5.71372032e+00 4.79847461e-01 1.86233177e+01 5.70495033e+00\n",
      "  1.33689604e+01 7.33467913e+00 2.90349436e+00 4.97561169e+00\n",
      "  7.06024218e+00 3.69937979e-02 3.20427748e-03 5.01498207e-03\n",
      "  2.00467203e-02 5.09915650e-02 2.34044716e-01 1.02075970e+00\n",
      "  1.95539629e+00 1.82360590e+00 3.46882045e-01 2.74892807e-01\n",
      "  6.38963223e-01 1.21769965e+00 5.21588135e+00 5.19229412e+00\n",
      "  4.59493971e+00 5.22125006e+00 1.79083288e+00 1.05123115e+00\n",
      "  1.34268248e+00 1.26411211e+00 7.06894636e-01 2.71861625e+00\n",
      "  6.48447323e+00 8.18231106e+00 5.30337763e+00 1.15475392e+00\n",
      "  1.40012848e+00 1.42729211e+00 4.25726444e-01 6.31143451e-01\n",
      "  3.74164867e+00 1.42261422e+00 5.20868599e-01 1.69776380e-01\n",
      "  5.95429726e-02 1.16274528e-01 3.37938070e-01 7.51698852e-01\n",
      "  1.19374491e-01 7.71171302e-02 7.53467977e-02 2.20026001e-01\n",
      "  7.40211666e-01 4.00744706e-01 7.99848810e-02 8.15171748e-02\n",
      "  1.39886543e-01 3.38773519e-01 2.70554036e-01 6.38480857e-02\n",
      "  9.13160965e-02 4.10855591e-01 4.75272536e-01 1.16297200e-01\n",
      "  4.92560089e-01 7.29813337e-01 4.50295329e-01 3.27019036e-01\n",
      "  4.32175785e-01 4.81991887e-01 1.13434470e+00 1.06815648e+00\n",
      "  5.04962981e-01 3.59041125e-01 3.48261923e-01 2.20323384e-01\n",
      "  1.72291338e-01 3.79264981e-01 3.32638085e-01 3.47907543e-01\n",
      "  3.79966289e-01 3.87374163e-01 3.86047423e-01 1.86100498e-01\n",
      "  2.56720185e-01 1.02153815e-01 1.76144205e-02 3.99360061e-02\n",
      "  1.70494802e-02 1.83322541e-02 1.11799724e-02 9.00361408e-03\n",
      "  5.94953727e-03 1.47892945e-02 2.64421441e-02 3.95192504e-02\n",
      "  4.58624363e-02 6.74429759e-02 7.54906386e-02 7.48549476e-02\n",
      "  4.96814847e-02 9.03537124e-02 2.72669531e-02 4.37543951e-02\n",
      "  1.14607830e-02 1.10944007e-02 3.83997988e-03 3.91697837e-03\n",
      "  3.87844420e-03 2.13372754e-03 1.92389078e-03 1.63224281e-03\n",
      "  2.04629428e-03 3.37145058e-03 2.66461424e-03 1.92620372e-03\n",
      "  6.11679023e-03 6.40896196e-03 7.89144635e-03 1.13572292e-02\n",
      "  2.00129058e-02 8.62524100e-03 3.49917309e-03 1.49912806e-03\n",
      "  4.59183575e-05 8.43294572e-07 2.04631746e-07 1.80217953e-07\n",
      "  1.63622346e-07 1.51237643e-07 1.41428671e-07 1.33790991e-07\n",
      "  1.27589956e-07 1.22599047e-07 1.18728778e-07 1.15740740e-07\n",
      "  1.13680493e-07 1.12380008e-07]\n",
      " [1.59756747e-01 7.37597837e-01 7.65547433e-01 7.84216334e-01\n",
      "  7.85036668e-01 7.69361334e-01 7.04499763e-01 6.21089487e-01\n",
      "  6.34926405e-01 7.28144085e-01 7.74584292e-01 8.37707632e-01\n",
      "  8.07577805e-01 2.71805653e+02 6.50659454e+01 1.26552529e+00\n",
      "  2.74483548e+01 1.29718681e+01 7.19491324e-02 1.40577956e+01\n",
      "  4.65404344e+00 3.84004891e+00 7.13100644e+00 1.22938539e+01\n",
      "  3.98410628e+00 3.62998031e+00 1.24913703e+01 3.20095962e-01\n",
      "  7.96749006e+00 9.53803815e+00 3.22849832e+00 5.63106132e+00\n",
      "  6.60704803e+00 3.72921057e-02 3.66905461e-03 5.46434019e-03\n",
      "  2.07990845e-02 5.16847018e-02 2.34714983e-01 1.02702489e+00\n",
      "  1.95651327e+00 1.83148825e+00 3.46261974e-01 2.76853947e-01\n",
      "  6.41894521e-01 1.22138051e+00 5.20413960e+00 5.18593519e+00\n",
      "  4.59061844e+00 5.22176236e+00 1.79971095e+00 1.05280926e+00\n",
      "  1.34792932e+00 1.26563498e+00 7.05420758e-01 2.72094504e+00\n",
      "  6.49146547e+00 8.18242555e+00 5.30657578e+00 1.15298101e+00\n",
      "  1.40158316e+00 1.43127846e+00 4.28837393e-01 6.29517345e-01\n",
      "  3.73548214e+00 1.42240933e+00 5.16564001e-01 1.71772772e-01\n",
      "  6.00533443e-02 1.17282880e-01 3.39306896e-01 7.53810831e-01\n",
      "  1.19688916e-01 7.87342704e-02 7.65047495e-02 2.22102739e-01\n",
      "  7.40901831e-01 4.04031803e-01 8.22254253e-02 8.22797581e-02\n",
      "  1.40372630e-01 3.43399491e-01 2.71023313e-01 6.43908299e-02\n",
      "  9.23536789e-02 4.09781796e-01 4.74666276e-01 1.16528058e-01\n",
      "  4.95903122e-01 7.30966076e-01 4.49276385e-01 3.27121406e-01\n",
      "  4.34660820e-01 4.83018363e-01 1.12855198e+00 1.06424517e+00\n",
      "  5.05966016e-01 3.58048219e-01 3.51216371e-01 2.21485274e-01\n",
      "  1.73422951e-01 3.80224462e-01 3.32618872e-01 3.47645729e-01\n",
      "  3.81345511e-01 3.90106760e-01 3.88831617e-01 1.87653534e-01\n",
      "  2.57558105e-01 1.02783744e-01 1.79449242e-02 4.03906243e-02\n",
      "  1.76429642e-02 1.85678558e-02 1.15726091e-02 9.42264239e-03\n",
      "  6.23030823e-03 1.48676421e-02 2.64137378e-02 3.90713770e-02\n",
      "  4.61324548e-02 6.79835030e-02 7.57063632e-02 7.56608793e-02\n",
      "  5.01350351e-02 9.11216326e-02 2.75926489e-02 4.39113120e-02\n",
      "  1.18598150e-02 1.11317344e-02 4.23690006e-03 4.36419632e-03\n",
      "  4.32575069e-03 2.55340367e-03 2.50203711e-03 2.11682681e-03\n",
      "  2.41354312e-03 3.61164267e-03 2.97829253e-03 2.25690872e-03\n",
      "  6.42906226e-03 6.82746581e-03 8.10954067e-03 1.16573609e-02\n",
      "  2.06086406e-02 8.97702999e-03 3.86320320e-03 1.87237932e-03\n",
      "  4.26821453e-04 3.68978811e-04 3.47468987e-04 3.34439387e-04\n",
      "  3.79400164e-04 3.98313566e-04 3.92177654e-04 3.66903828e-04\n",
      "  3.52567463e-04 3.29242580e-04 3.38384312e-04 3.29970779e-04\n",
      "  3.32460130e-04 3.59144666e-04]\n",
      " [8.35739357e-02 6.90334022e-01 7.02411056e-01 7.40429163e-01\n",
      "  7.33301163e-01 7.12178707e-01 6.21229827e-01 5.40060878e-01\n",
      "  6.04718387e-01 7.39202559e-01 7.20715284e-01 7.58589745e-01\n",
      "  7.68749654e-01 4.05396912e+02 1.18733253e+02 2.21543884e+01\n",
      "  4.36316605e+01 7.27990508e-01 6.71700048e+00 2.85811234e+01\n",
      "  4.91780853e+00 7.91136789e+00 7.25105572e+00 1.27493210e+01\n",
      "  3.85010511e-01 5.22166252e+00 1.38904591e+01 6.02476501e+00\n",
      "  1.72038155e+01 3.81869817e+00 5.90107155e+00 4.06642771e+00\n",
      "  9.49758720e+00 1.97854955e-02 6.26131485e-04 1.00154849e-03\n",
      "  5.89412730e-03 1.97527036e-02 5.43926023e-02 3.52241278e-01\n",
      "  4.65432048e-01 4.81373549e-01 2.35662714e-01 4.98836786e-02\n",
      "  2.06503168e-01 3.06045711e-01 4.86654192e-01 4.95615363e-01\n",
      "  5.20404756e-01 1.75879955e+00 1.07537460e+00 2.49437824e-01\n",
      "  1.39477059e-01 6.63336337e-01 2.55184114e-01 1.69466704e-01\n",
      "  1.00800753e+00 1.99729061e+00 2.85622263e+00 1.27543867e+00\n",
      "  2.68505096e-01 2.96413898e-01 4.28374797e-01 1.74848646e-01\n",
      "  7.24899173e-02 1.28657258e+00 9.22382236e-01 2.11538509e-01\n",
      "  1.06177099e-01 3.38400193e-02 2.66458355e-02 3.17672268e-02\n",
      "  3.12317461e-01 1.48441896e-01 3.21962498e-02 1.79292336e-02\n",
      "  2.05496754e-02 1.22649528e-01 2.21208215e-01 4.32156809e-02\n",
      "  2.07791608e-02 3.76157537e-02 5.11494912e-02 7.86515698e-02\n",
      "  7.51284063e-02 1.33855501e-02 8.51007327e-02 2.81020015e-01\n",
      "  5.10976687e-02 6.72447234e-02 1.64084524e-01 1.15131691e-01\n",
      "  9.66478214e-02 1.35451540e-01 1.41095802e-01 1.44473165e-01\n",
      "  5.39627612e-01 2.65438497e-01 1.69624865e-01 1.26449615e-01\n",
      "  2.12898716e-01 3.94810960e-02 9.02915299e-02 1.48072362e-01\n",
      "  1.14965796e-01 1.65721387e-01 1.03109315e-01 2.41413921e-01\n",
      "  1.04296356e-01 9.70077813e-02 1.00117981e-01 1.10549023e-02\n",
      "  8.12266767e-03 1.17342938e-02 4.04084753e-03 5.93964895e-03\n",
      "  4.59093694e-03 1.51213724e-03 4.91497340e-03 4.71198699e-03\n",
      "  1.09306118e-02 1.57644153e-02 1.90241262e-02 3.22767012e-02\n",
      "  3.35316733e-02 2.17437465e-02 3.32583226e-02 2.97343656e-02\n",
      "  1.04306908e-02 7.90343247e-03 4.30211471e-03 2.02228967e-03\n",
      "  9.93371708e-04 7.22827506e-04 1.16889260e-03 4.34967194e-04\n",
      "  5.45369519e-04 4.40554897e-04 5.89574338e-04 5.96623227e-04\n",
      "  5.22583025e-04 1.03095255e-03 1.94770854e-03 1.53372472e-03\n",
      "  3.13394587e-03 4.08380944e-03 4.47900407e-03 2.06501293e-03\n",
      "  5.99505845e-04 8.72094242e-05 2.68601525e-06 1.82851366e-07\n",
      "  1.50003970e-07 1.35035108e-07 1.23998916e-07 1.15946285e-07\n",
      "  1.09840890e-07 1.03162044e-07 8.65826308e-08 5.72030459e-08\n",
      "  3.21768034e-08 2.24156231e-08]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "[['fear']\n",
      " ['fear']\n",
      " ['fear']]\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(get_features('CREMA-D/AudioWAV/1001_DFA_HAP_XX.wav'))\n",
    "print(get_features('CREMA-D/AudioWAV/1001_DFA_HAP_XX.wav'))\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "print(pred_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.73909312],\n",
       "        [1.04469933],\n",
       "        [0.05233815],\n",
       "        ...,\n",
       "        [0.21289193],\n",
       "        [0.20891348],\n",
       "        [0.20839369]],\n",
       "\n",
       "       [[0.33936484],\n",
       "        [0.29043581],\n",
       "        [0.5498097 ],\n",
       "        ...,\n",
       "        [0.02528406],\n",
       "        [0.00435146],\n",
       "        [0.01184707]],\n",
       "\n",
       "       [[2.26407125],\n",
       "        [1.42366908],\n",
       "        [2.25730144],\n",
       "        ...,\n",
       "        [0.67114604],\n",
       "        [0.78191769],\n",
       "        [0.6853034 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.82157999],\n",
       "        [0.03155383],\n",
       "        [0.27223549],\n",
       "        ...,\n",
       "        [0.21272954],\n",
       "        [0.20882208],\n",
       "        [0.20833009]],\n",
       "\n",
       "       [[0.90371594],\n",
       "        [0.02609693],\n",
       "        [0.32631995],\n",
       "        ...,\n",
       "        [0.10187439],\n",
       "        [0.09802629],\n",
       "        [0.09140539]],\n",
       "\n",
       "       [[0.24070205],\n",
       "        [0.1755817 ],\n",
       "        [0.69508417],\n",
       "        ...,\n",
       "        [0.21292212],\n",
       "        [0.20893059],\n",
       "        [0.20840564]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (85272) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPredicted Labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mActual Labels\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mPredicted Labels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m----> 3\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mActual Labels\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3978\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3975\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3976\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3977\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3978\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4172\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4163\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4170\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4171\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4172\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4174\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4175\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4176\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4177\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4178\u001b[0m     ):\n\u001b[1;32m   4179\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4180\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4909\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4911\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4912\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4913\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (85272) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "while True:\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"* done recording\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    audioFile = get_features(WAVE_OUTPUT_FILENAME)\n",
    "    sent = model.predict(audioFile)\n",
    "    sentiment = encoder.inverse_transform(sent)\n",
    "    print(sentiment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = get_features('CREMA-D/AudioWAV/1001_ITH_NEU_XX.wav')\n",
    "breh = model.predict(thing)\n",
    "print(breh)\n",
    "print(encoder.inverse_transform(breh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "pred_test = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "\n",
    "y_test = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "\"\"\"\n",
    "3=angry\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema_df['Emotions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
