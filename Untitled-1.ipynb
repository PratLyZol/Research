{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = 'CREMA-D/AudioWAV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Crema_df\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "path = np.array(data_path.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>happy</td>\n",
       "      <td>CREMA-D/AudioWAV/1090_TAI_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>angry</td>\n",
       "      <td>CREMA-D/AudioWAV/1061_IOM_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITS_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1055_MTI_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>happy</td>\n",
       "      <td>CREMA-D/AudioWAV/1087_IEO_HAP_LO.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotions                                  Path\n",
       "0        fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1     disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2     disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3         sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4     neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav\n",
       "...       ...                                   ...\n",
       "7437    happy  CREMA-D/AudioWAV/1090_TAI_HAP_XX.wav\n",
       "7438    angry  CREMA-D/AudioWAV/1061_IOM_ANG_XX.wav\n",
       "7439  disgust  CREMA-D/AudioWAV/1067_ITS_DIS_XX.wav\n",
       "7440     fear  CREMA-D/AudioWAV/1055_MTI_FEA_XX.wav\n",
       "7441    happy  CREMA-D/AudioWAV/1087_IEO_HAP_LO.wav\n",
       "\n",
       "[7442 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(data_path.Path, data_path.Emotions):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22326, 22326, (7442,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.637844</td>\n",
       "      <td>0.606111</td>\n",
       "      <td>0.571997</td>\n",
       "      <td>0.630106</td>\n",
       "      <td>0.714430</td>\n",
       "      <td>0.675026</td>\n",
       "      <td>0.665222</td>\n",
       "      <td>0.719204</td>\n",
       "      <td>0.826163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242615e-10</td>\n",
       "      <td>2.971604e-10</td>\n",
       "      <td>2.766176e-10</td>\n",
       "      <td>2.603836e-10</td>\n",
       "      <td>2.475797e-10</td>\n",
       "      <td>2.377858e-10</td>\n",
       "      <td>2.303247e-10</td>\n",
       "      <td>2.252069e-10</td>\n",
       "      <td>2.220143e-10</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101535</td>\n",
       "      <td>0.714208</td>\n",
       "      <td>0.699778</td>\n",
       "      <td>0.658751</td>\n",
       "      <td>0.701831</td>\n",
       "      <td>0.777295</td>\n",
       "      <td>0.703174</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.717846</td>\n",
       "      <td>0.824534</td>\n",
       "      <td>...</td>\n",
       "      <td>1.585005e-04</td>\n",
       "      <td>1.521305e-04</td>\n",
       "      <td>1.492612e-04</td>\n",
       "      <td>1.572536e-04</td>\n",
       "      <td>1.516591e-04</td>\n",
       "      <td>1.498361e-04</td>\n",
       "      <td>1.503378e-04</td>\n",
       "      <td>1.450021e-04</td>\n",
       "      <td>1.499775e-04</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059451</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.640867</td>\n",
       "      <td>0.584112</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.634756</td>\n",
       "      <td>0.718933</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>0.665793</td>\n",
       "      <td>0.731998</td>\n",
       "      <td>...</td>\n",
       "      <td>1.885746e-10</td>\n",
       "      <td>1.724273e-10</td>\n",
       "      <td>1.642871e-10</td>\n",
       "      <td>1.507513e-10</td>\n",
       "      <td>1.506967e-10</td>\n",
       "      <td>1.413461e-10</td>\n",
       "      <td>1.223686e-10</td>\n",
       "      <td>1.028102e-10</td>\n",
       "      <td>9.267615e-11</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059764</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.392475</td>\n",
       "      <td>0.459169</td>\n",
       "      <td>0.471746</td>\n",
       "      <td>0.485209</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.797795</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.943509e-08</td>\n",
       "      <td>3.484132e-08</td>\n",
       "      <td>3.144174e-08</td>\n",
       "      <td>2.883970e-08</td>\n",
       "      <td>2.684491e-08</td>\n",
       "      <td>2.534668e-08</td>\n",
       "      <td>2.423224e-08</td>\n",
       "      <td>2.347231e-08</td>\n",
       "      <td>2.300906e-08</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085024</td>\n",
       "      <td>0.450105</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>0.530033</td>\n",
       "      <td>0.538887</td>\n",
       "      <td>0.540810</td>\n",
       "      <td>0.661029</td>\n",
       "      <td>0.801628</td>\n",
       "      <td>0.779178</td>\n",
       "      <td>0.631612</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244623e-04</td>\n",
       "      <td>1.194900e-04</td>\n",
       "      <td>1.205693e-04</td>\n",
       "      <td>1.168062e-04</td>\n",
       "      <td>1.209767e-04</td>\n",
       "      <td>1.212355e-04</td>\n",
       "      <td>1.206974e-04</td>\n",
       "      <td>1.262865e-04</td>\n",
       "      <td>1.236092e-04</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.053580  0.637844  0.606111  0.571997  0.630106  0.714430  0.675026   \n",
       "1  0.101535  0.714208  0.699778  0.658751  0.701831  0.777295  0.703174   \n",
       "2  0.059451  0.583235  0.640867  0.584112  0.567250  0.634756  0.718933   \n",
       "3  0.059764  0.452337  0.392475  0.459169  0.471746  0.485209  0.507530   \n",
       "4  0.085024  0.450105  0.495852  0.530033  0.538887  0.540810  0.661029   \n",
       "\n",
       "          7         8         9  ...           153           154  \\\n",
       "0  0.665222  0.719204  0.826163  ...  3.242615e-10  2.971604e-10   \n",
       "1  0.678100  0.717846  0.824534  ...  1.585005e-04  1.521305e-04   \n",
       "2  0.701798  0.665793  0.731998  ...  1.885746e-10  1.724273e-10   \n",
       "3  0.684371  0.797795  0.724068  ...  3.943509e-08  3.484132e-08   \n",
       "4  0.801628  0.779178  0.631612  ...  1.244623e-04  1.194900e-04   \n",
       "\n",
       "            155           156           157           158           159  \\\n",
       "0  2.766176e-10  2.603836e-10  2.475797e-10  2.377858e-10  2.303247e-10   \n",
       "1  1.492612e-04  1.572536e-04  1.516591e-04  1.498361e-04  1.503378e-04   \n",
       "2  1.642871e-10  1.507513e-10  1.506967e-10  1.413461e-10  1.223686e-10   \n",
       "3  3.144174e-08  2.883970e-08  2.684491e-08  2.534668e-08  2.423224e-08   \n",
       "4  1.205693e-04  1.168062e-04  1.209767e-04  1.212355e-04  1.206974e-04   \n",
       "\n",
       "            160           161   labels  \n",
       "0  2.252069e-10  2.220143e-10     fear  \n",
       "1  1.450021e-04  1.499775e-04     fear  \n",
       "2  1.028102e-10  9.267615e-11     fear  \n",
       "3  2.347231e-08  2.300906e-08  disgust  \n",
       "4  1.262865e-04  1.236092e-04  disgust  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162), (16744, 6), (5582, 162), (5582, 6))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162), (16744, 6), (5582, 162), (5582, 6))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16744, 162, 1), (16744, 6), (5582, 162, 1), (5582, 6))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 162, 256)          1536      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 81, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 81, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 41, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 21, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 21, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 11, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 704)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                22560     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557,222\n",
      "Trainable params: 557,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 1.5976 - accuracy: 0.3223 - val_loss: 1.5145 - val_accuracy: 0.3637 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.5135 - accuracy: 0.3623 - val_loss: 1.4692 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "262/262 [==============================] - 10s 39ms/step - loss: 1.4855 - accuracy: 0.3884 - val_loss: 1.4558 - val_accuracy: 0.4072 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.4593 - accuracy: 0.3962 - val_loss: 1.4105 - val_accuracy: 0.4104 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "262/262 [==============================] - 10s 39ms/step - loss: 1.4402 - accuracy: 0.4061 - val_loss: 1.4053 - val_accuracy: 0.4203 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.4202 - accuracy: 0.4220 - val_loss: 1.3915 - val_accuracy: 0.4276 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.4028 - accuracy: 0.4302 - val_loss: 1.3668 - val_accuracy: 0.4439 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.3903 - accuracy: 0.4338 - val_loss: 1.3746 - val_accuracy: 0.4296 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3766 - accuracy: 0.4387 - val_loss: 1.3552 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3608 - accuracy: 0.4550 - val_loss: 1.3681 - val_accuracy: 0.4488 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3481 - accuracy: 0.4536 - val_loss: 1.3330 - val_accuracy: 0.4566 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3306 - accuracy: 0.4612 - val_loss: 1.3384 - val_accuracy: 0.4618 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.3178 - accuracy: 0.4672 - val_loss: 1.3335 - val_accuracy: 0.4629 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.2980 - accuracy: 0.4778 - val_loss: 1.3598 - val_accuracy: 0.4384 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.2870 - accuracy: 0.4808 - val_loss: 1.3177 - val_accuracy: 0.4663 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.2698 - accuracy: 0.4879 - val_loss: 1.2947 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.2562 - accuracy: 0.4983 - val_loss: 1.3111 - val_accuracy: 0.4760 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.2450 - accuracy: 0.4988 - val_loss: 1.3123 - val_accuracy: 0.4735 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.2272 - accuracy: 0.5098 - val_loss: 1.3024 - val_accuracy: 0.4753 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.2100 - accuracy: 0.5163 - val_loss: 1.2987 - val_accuracy: 0.4833 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1962 - accuracy: 0.5224 - val_loss: 1.3019 - val_accuracy: 0.4755 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.1765 - accuracy: 0.5292 - val_loss: 1.3170 - val_accuracy: 0.4697 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.1650 - accuracy: 0.5325 - val_loss: 1.2903 - val_accuracy: 0.4873 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.1517 - accuracy: 0.5435 - val_loss: 1.2942 - val_accuracy: 0.4833 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1445 - accuracy: 0.5460 - val_loss: 1.2983 - val_accuracy: 0.4778 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1217 - accuracy: 0.5556 - val_loss: 1.2841 - val_accuracy: 0.4905 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.1137 - accuracy: 0.5549 - val_loss: 1.2874 - val_accuracy: 0.4936 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 1.0869 - accuracy: 0.5638 - val_loss: 1.3051 - val_accuracy: 0.4815 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.0804 - accuracy: 0.5698 - val_loss: 1.3005 - val_accuracy: 0.4889 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "262/262 [==============================] - 10s 39ms/step - loss: 1.0583 - accuracy: 0.5767 - val_loss: 1.3176 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.0579 - accuracy: 0.5818 - val_loss: 1.3260 - val_accuracy: 0.4937 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.0274 - accuracy: 0.5900 - val_loss: 1.3055 - val_accuracy: 0.4903 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.0166 - accuracy: 0.5935 - val_loss: 1.3241 - val_accuracy: 0.4934 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.0149 - accuracy: 0.5965 - val_loss: 1.3623 - val_accuracy: 0.4885 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 1.0080 - accuracy: 0.6006 - val_loss: 1.3381 - val_accuracy: 0.4835 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.9723 - accuracy: 0.6131 - val_loss: 1.3318 - val_accuracy: 0.4842 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.9685 - accuracy: 0.6150 - val_loss: 1.3631 - val_accuracy: 0.4864 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.9609 - accuracy: 0.6189 - val_loss: 1.4059 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.9429 - accuracy: 0.6330 - val_loss: 1.3454 - val_accuracy: 0.4916 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.9374 - accuracy: 0.6297 - val_loss: 1.3442 - val_accuracy: 0.4971 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.9313 - accuracy: 0.6306 - val_loss: 1.3587 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.8988 - accuracy: 0.6474 - val_loss: 1.3979 - val_accuracy: 0.5004 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.8966 - accuracy: 0.6460 - val_loss: 1.3731 - val_accuracy: 0.4932 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.8886 - accuracy: 0.6516 - val_loss: 1.4015 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 45/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.8686 - accuracy: 0.6565 - val_loss: 1.4115 - val_accuracy: 0.4955 - lr: 0.0010\n",
      "Epoch 46/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.8486 - accuracy: 0.6656 - val_loss: 1.4399 - val_accuracy: 0.4939 - lr: 0.0010\n",
      "Epoch 47/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.8440 - accuracy: 0.6671 - val_loss: 1.4442 - val_accuracy: 0.4936 - lr: 0.0010\n",
      "Epoch 48/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.8379 - accuracy: 0.6696 - val_loss: 1.4735 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 49/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.8248 - accuracy: 0.6717 - val_loss: 1.4476 - val_accuracy: 0.4885 - lr: 0.0010\n",
      "Epoch 50/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8239 - accuracy: 0.6799 - val_loss: 1.4768 - val_accuracy: 0.4894 - lr: 0.0010\n",
      "Epoch 51/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8020 - accuracy: 0.6879 - val_loss: 1.4752 - val_accuracy: 0.4987 - lr: 0.0010\n",
      "Epoch 52/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.8106 - accuracy: 0.6857 - val_loss: 1.5034 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 53/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.7792 - accuracy: 0.6955 - val_loss: 1.4946 - val_accuracy: 0.4993 - lr: 0.0010\n",
      "Epoch 54/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.7992 - accuracy: 0.6936 - val_loss: 1.4981 - val_accuracy: 0.4998 - lr: 0.0010\n",
      "Epoch 55/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.7809 - accuracy: 0.6951 - val_loss: 1.5161 - val_accuracy: 0.4993 - lr: 0.0010\n",
      "Epoch 56/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.6777 - accuracy: 0.7366 - val_loss: 1.5666 - val_accuracy: 0.5073 - lr: 4.0000e-04\n",
      "Epoch 57/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.6487 - accuracy: 0.7479 - val_loss: 1.5549 - val_accuracy: 0.5066 - lr: 4.0000e-04\n",
      "Epoch 58/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.6244 - accuracy: 0.7548 - val_loss: 1.6326 - val_accuracy: 0.5104 - lr: 4.0000e-04\n",
      "Epoch 59/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.6171 - accuracy: 0.7615 - val_loss: 1.6232 - val_accuracy: 0.5036 - lr: 4.0000e-04\n",
      "Epoch 60/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.6073 - accuracy: 0.7636 - val_loss: 1.6738 - val_accuracy: 0.5032 - lr: 4.0000e-04\n",
      "Epoch 61/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.6001 - accuracy: 0.7667 - val_loss: 1.6720 - val_accuracy: 0.5075 - lr: 4.0000e-04\n",
      "Epoch 62/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5873 - accuracy: 0.7688 - val_loss: 1.7505 - val_accuracy: 0.4991 - lr: 4.0000e-04\n",
      "Epoch 63/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5764 - accuracy: 0.7762 - val_loss: 1.7263 - val_accuracy: 0.5038 - lr: 4.0000e-04\n",
      "Epoch 64/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5769 - accuracy: 0.7781 - val_loss: 1.7237 - val_accuracy: 0.5082 - lr: 4.0000e-04\n",
      "Epoch 65/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5743 - accuracy: 0.7746 - val_loss: 1.7690 - val_accuracy: 0.5088 - lr: 4.0000e-04\n",
      "Epoch 66/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5637 - accuracy: 0.7803 - val_loss: 1.7212 - val_accuracy: 0.5082 - lr: 4.0000e-04\n",
      "Epoch 67/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5517 - accuracy: 0.7856 - val_loss: 1.7503 - val_accuracy: 0.5029 - lr: 4.0000e-04\n",
      "Epoch 68/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5466 - accuracy: 0.7907 - val_loss: 1.8059 - val_accuracy: 0.5036 - lr: 4.0000e-04\n",
      "Epoch 69/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5352 - accuracy: 0.7924 - val_loss: 1.8407 - val_accuracy: 0.5029 - lr: 4.0000e-04\n",
      "Epoch 70/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5275 - accuracy: 0.7946 - val_loss: 1.8877 - val_accuracy: 0.4977 - lr: 4.0000e-04\n",
      "Epoch 71/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5263 - accuracy: 0.7963 - val_loss: 1.8409 - val_accuracy: 0.5011 - lr: 4.0000e-04\n",
      "Epoch 72/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5211 - accuracy: 0.7997 - val_loss: 1.8516 - val_accuracy: 0.5002 - lr: 4.0000e-04\n",
      "Epoch 73/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5074 - accuracy: 0.8039 - val_loss: 1.9087 - val_accuracy: 0.5054 - lr: 4.0000e-04\n",
      "Epoch 74/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.5069 - accuracy: 0.8025 - val_loss: 1.8829 - val_accuracy: 0.4991 - lr: 4.0000e-04\n",
      "Epoch 75/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.5133 - accuracy: 0.8021 - val_loss: 1.9185 - val_accuracy: 0.5014 - lr: 4.0000e-04\n",
      "Epoch 76/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.4987 - accuracy: 0.8097 - val_loss: 1.9489 - val_accuracy: 0.5005 - lr: 4.0000e-04\n",
      "Epoch 77/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.4831 - accuracy: 0.8155 - val_loss: 2.0048 - val_accuracy: 0.4980 - lr: 4.0000e-04\n",
      "Epoch 78/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4912 - accuracy: 0.8091 - val_loss: 1.9277 - val_accuracy: 0.5050 - lr: 4.0000e-04\n",
      "Epoch 79/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.4806 - accuracy: 0.8150 - val_loss: 2.0203 - val_accuracy: 0.5005 - lr: 4.0000e-04\n",
      "Epoch 80/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.4691 - accuracy: 0.8189 - val_loss: 1.9059 - val_accuracy: 0.5034 - lr: 4.0000e-04\n",
      "Epoch 81/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4667 - accuracy: 0.8259 - val_loss: 1.9833 - val_accuracy: 0.4971 - lr: 4.0000e-04\n",
      "Epoch 82/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4620 - accuracy: 0.8223 - val_loss: 2.0005 - val_accuracy: 0.5029 - lr: 4.0000e-04\n",
      "Epoch 83/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.4562 - accuracy: 0.8258 - val_loss: 2.0381 - val_accuracy: 0.5048 - lr: 4.0000e-04\n",
      "Epoch 84/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4591 - accuracy: 0.8224 - val_loss: 2.1089 - val_accuracy: 0.5048 - lr: 4.0000e-04\n",
      "Epoch 85/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.4455 - accuracy: 0.8307 - val_loss: 2.0979 - val_accuracy: 0.5005 - lr: 4.0000e-04\n",
      "Epoch 86/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4565 - accuracy: 0.8276 - val_loss: 1.9744 - val_accuracy: 0.5079 - lr: 4.0000e-04\n",
      "Epoch 87/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.4595 - accuracy: 0.8244 - val_loss: 2.0250 - val_accuracy: 0.5088 - lr: 4.0000e-04\n",
      "Epoch 88/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3978 - accuracy: 0.8499 - val_loss: 2.1737 - val_accuracy: 0.5113 - lr: 1.6000e-04\n",
      "Epoch 89/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3952 - accuracy: 0.8526 - val_loss: 2.1472 - val_accuracy: 0.5091 - lr: 1.6000e-04\n",
      "Epoch 90/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3812 - accuracy: 0.8561 - val_loss: 2.1702 - val_accuracy: 0.5070 - lr: 1.6000e-04\n",
      "Epoch 91/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3836 - accuracy: 0.8513 - val_loss: 2.1411 - val_accuracy: 0.5106 - lr: 1.6000e-04\n",
      "Epoch 92/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3739 - accuracy: 0.8616 - val_loss: 2.2151 - val_accuracy: 0.5050 - lr: 1.6000e-04\n",
      "Epoch 93/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3675 - accuracy: 0.8605 - val_loss: 2.2627 - val_accuracy: 0.5073 - lr: 1.6000e-04\n",
      "Epoch 94/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3694 - accuracy: 0.8591 - val_loss: 2.2070 - val_accuracy: 0.5064 - lr: 1.6000e-04\n",
      "Epoch 95/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3606 - accuracy: 0.8659 - val_loss: 2.2702 - val_accuracy: 0.5116 - lr: 1.6000e-04\n",
      "Epoch 96/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3604 - accuracy: 0.8644 - val_loss: 2.2809 - val_accuracy: 0.5122 - lr: 1.6000e-04\n",
      "Epoch 97/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3569 - accuracy: 0.8647 - val_loss: 2.2569 - val_accuracy: 0.5043 - lr: 1.6000e-04\n",
      "Epoch 98/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3554 - accuracy: 0.8657 - val_loss: 2.2930 - val_accuracy: 0.5045 - lr: 1.6000e-04\n",
      "Epoch 99/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3566 - accuracy: 0.8641 - val_loss: 2.3052 - val_accuracy: 0.5070 - lr: 1.6000e-04\n",
      "Epoch 100/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3576 - accuracy: 0.8640 - val_loss: 2.3061 - val_accuracy: 0.5032 - lr: 1.6000e-04\n",
      "Epoch 101/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3408 - accuracy: 0.8716 - val_loss: 2.3112 - val_accuracy: 0.5050 - lr: 6.4000e-05\n",
      "Epoch 102/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3310 - accuracy: 0.8751 - val_loss: 2.3353 - val_accuracy: 0.5068 - lr: 6.4000e-05\n",
      "Epoch 103/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3244 - accuracy: 0.8783 - val_loss: 2.3446 - val_accuracy: 0.5077 - lr: 6.4000e-05\n",
      "Epoch 104/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3259 - accuracy: 0.8763 - val_loss: 2.3448 - val_accuracy: 0.5063 - lr: 6.4000e-05\n",
      "Epoch 105/150\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.3282 - accuracy: 0.8770 - val_loss: 2.3489 - val_accuracy: 0.5021 - lr: 6.4000e-05\n",
      "Epoch 106/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3154 - accuracy: 0.8815 - val_loss: 2.3603 - val_accuracy: 0.5077 - lr: 2.5600e-05\n",
      "Epoch 107/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3167 - accuracy: 0.8805 - val_loss: 2.3662 - val_accuracy: 0.5082 - lr: 2.5600e-05\n",
      "Epoch 108/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3160 - accuracy: 0.8806 - val_loss: 2.3588 - val_accuracy: 0.5057 - lr: 2.5600e-05\n",
      "Epoch 109/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3095 - accuracy: 0.8846 - val_loss: 2.3644 - val_accuracy: 0.5056 - lr: 1.0240e-05\n",
      "Epoch 110/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3116 - accuracy: 0.8844 - val_loss: 2.3673 - val_accuracy: 0.5070 - lr: 1.0240e-05\n",
      "Epoch 111/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3111 - accuracy: 0.8839 - val_loss: 2.3675 - val_accuracy: 0.5068 - lr: 1.0240e-05\n",
      "Epoch 112/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3071 - accuracy: 0.8824 - val_loss: 2.3683 - val_accuracy: 0.5072 - lr: 4.0960e-06\n",
      "Epoch 113/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3079 - accuracy: 0.8846 - val_loss: 2.3708 - val_accuracy: 0.5066 - lr: 4.0960e-06\n",
      "Epoch 114/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3085 - accuracy: 0.8853 - val_loss: 2.3725 - val_accuracy: 0.5077 - lr: 4.0960e-06\n",
      "Epoch 115/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3098 - accuracy: 0.8837 - val_loss: 2.3727 - val_accuracy: 0.5077 - lr: 1.6384e-06\n",
      "Epoch 116/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3009 - accuracy: 0.8865 - val_loss: 2.3731 - val_accuracy: 0.5081 - lr: 1.6384e-06\n",
      "Epoch 117/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3075 - accuracy: 0.8823 - val_loss: 2.3738 - val_accuracy: 0.5073 - lr: 1.6384e-06\n",
      "Epoch 118/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3114 - accuracy: 0.8817 - val_loss: 2.3737 - val_accuracy: 0.5079 - lr: 1.6384e-06\n",
      "Epoch 119/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3104 - accuracy: 0.8838 - val_loss: 2.3743 - val_accuracy: 0.5075 - lr: 6.5536e-07\n",
      "Epoch 120/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3068 - accuracy: 0.8837 - val_loss: 2.3745 - val_accuracy: 0.5075 - lr: 6.5536e-07\n",
      "Epoch 121/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3102 - accuracy: 0.8834 - val_loss: 2.3745 - val_accuracy: 0.5077 - lr: 2.6214e-07\n",
      "Epoch 122/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.3129 - accuracy: 0.8826 - val_loss: 2.3744 - val_accuracy: 0.5081 - lr: 2.6214e-07\n",
      "Epoch 123/150\n",
      "262/262 [==============================] - 10s 39ms/step - loss: 0.3073 - accuracy: 0.8849 - val_loss: 2.3744 - val_accuracy: 0.5079 - lr: 1.0486e-07\n",
      "Epoch 124/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3068 - accuracy: 0.8849 - val_loss: 2.3745 - val_accuracy: 0.5081 - lr: 1.0486e-07\n",
      "Epoch 125/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3032 - accuracy: 0.8856 - val_loss: 2.3746 - val_accuracy: 0.5079 - lr: 1.0000e-07\n",
      "Epoch 126/150\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.3095 - accuracy: 0.8846 - val_loss: 2.3746 - val_accuracy: 0.5081 - lr: 1.0000e-07\n",
      "Epoch 127/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3068 - accuracy: 0.8860 - val_loss: 2.3746 - val_accuracy: 0.5082 - lr: 1.0000e-07\n",
      "Epoch 128/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3111 - accuracy: 0.8838 - val_loss: 2.3746 - val_accuracy: 0.5079 - lr: 1.0000e-07\n",
      "Epoch 129/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3036 - accuracy: 0.8874 - val_loss: 2.3746 - val_accuracy: 0.5079 - lr: 1.0000e-07\n",
      "Epoch 130/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3084 - accuracy: 0.8836 - val_loss: 2.3747 - val_accuracy: 0.5079 - lr: 1.0000e-07\n",
      "Epoch 131/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3039 - accuracy: 0.8852 - val_loss: 2.3748 - val_accuracy: 0.5081 - lr: 1.0000e-07\n",
      "Epoch 132/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3075 - accuracy: 0.8853 - val_loss: 2.3748 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 133/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3084 - accuracy: 0.8847 - val_loss: 2.3748 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 134/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3076 - accuracy: 0.8850 - val_loss: 2.3749 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 135/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3092 - accuracy: 0.8840 - val_loss: 2.3749 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 136/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3012 - accuracy: 0.8866 - val_loss: 2.3751 - val_accuracy: 0.5075 - lr: 1.0000e-07\n",
      "Epoch 137/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3093 - accuracy: 0.8838 - val_loss: 2.3750 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 138/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3052 - accuracy: 0.8840 - val_loss: 2.3751 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 139/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3077 - accuracy: 0.8853 - val_loss: 2.3751 - val_accuracy: 0.5079 - lr: 1.0000e-07\n",
      "Epoch 140/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3066 - accuracy: 0.8867 - val_loss: 2.3751 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 141/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3019 - accuracy: 0.8840 - val_loss: 2.3752 - val_accuracy: 0.5079 - lr: 1.0000e-07\n",
      "Epoch 142/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.2996 - accuracy: 0.8843 - val_loss: 2.3753 - val_accuracy: 0.5079 - lr: 1.0000e-07\n",
      "Epoch 143/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3030 - accuracy: 0.8865 - val_loss: 2.3753 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 144/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3111 - accuracy: 0.8838 - val_loss: 2.3753 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 145/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3065 - accuracy: 0.8825 - val_loss: 2.3754 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 146/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3174 - accuracy: 0.8817 - val_loss: 2.3754 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 147/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.3044 - accuracy: 0.8843 - val_loss: 2.3755 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 148/150\n",
      "262/262 [==============================] - 11s 41ms/step - loss: 0.3036 - accuracy: 0.8848 - val_loss: 2.3756 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 149/150\n",
      "262/262 [==============================] - 11s 40ms/step - loss: 0.3038 - accuracy: 0.8860 - val_loss: 2.3757 - val_accuracy: 0.5077 - lr: 1.0000e-07\n",
      "Epoch 150/150\n",
      "262/262 [==============================] - 10s 40ms/step - loss: 0.3023 - accuracy: 0.8842 - val_loss: 2.3756 - val_accuracy: 0.5077 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=150, validation_data=(x_test, y_test), callbacks=[rlrp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
