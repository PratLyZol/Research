{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = 'CREMA-D/AudioWAV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-03-01-02-02-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-05-02-02-02-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprise</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-08-02-02-02-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calm</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-02-01-01-01-02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>RAVDESS/Actor_02/03-01-08-01-01-01-02.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotions                                       Path\n",
       "0     happy  RAVDESS/Actor_02/03-01-03-01-02-02-02.wav\n",
       "1     angry  RAVDESS/Actor_02/03-01-05-02-02-02-02.wav\n",
       "2  surprise  RAVDESS/Actor_02/03-01-08-02-02-02-02.wav\n",
       "3      calm  RAVDESS/Actor_02/03-01-02-01-01-01-02.wav\n",
       "4  surprise  RAVDESS/Actor_02/03-01-08-01-01-01-02.wav"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "ravdess_dir = os.listdir('RAVDESS')\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for dir in ravdess_dir:\n",
    "    actor = os.listdir('RAVDESS/' + dir)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append('RAVDESS/' + dir + '/' + file)\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)   \n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':    \n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_pleasant_surprised\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_sad\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/OAF_Sad\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_happy\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_fear\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/OAF_Fear\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/OAF_disgust\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_disgust\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/OAF_happy\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/OAF_angry\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_angry\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/OAF_neutral\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_neutral\n",
      "archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/OAF_Pleasant_surprise\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>archive/tess toronto emotional speech set data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotions                                               Path\n",
       "0  surprise  archive/tess toronto emotional speech set data...\n",
       "1  surprise  archive/tess toronto emotional speech set data...\n",
       "2  surprise  archive/tess toronto emotional speech set data...\n",
       "3  surprise  archive/tess toronto emotional speech set data...\n",
       "4  surprise  archive/tess toronto emotional speech set data..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tess = 'archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data'\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + '/' + dir)\n",
    "    print(Tess+'/'+dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + '/' + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0     fear  CREMA-D/AudioWAV/1025_TIE_FEA_XX.wav\n",
       "1  disgust  CREMA-D/AudioWAV/1054_MTI_DIS_XX.wav\n",
       "2  disgust  CREMA-D/AudioWAV/1052_IOM_DIS_XX.wav\n",
       "3      sad  CREMA-D/AudioWAV/1067_ITH_SAD_XX.wav\n",
       "4  neutral  CREMA-D/AudioWAV/1091_ITH_NEU_XX.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing = [Crema_df, Ravdess_df, Tess_df]\n",
    "data_path = pd.concat(thing)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "path = np.array(data_path.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return abs(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_83757/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_83757/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "4388it [17:05,  4.67it/s]/home/prat/.local/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n",
      "11682it [47:51,  4.07it/s]\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "from tqdm import tqdm\n",
    "for path, emotion in tqdm(zip(data_path.Path, data_path.Emotions)):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35046, 35046, (11682,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_309248/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_309248/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features('CREMA-D/AudioWAV/1001_DFA_ANG_XX.wav').size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.637844</td>\n",
       "      <td>0.606111</td>\n",
       "      <td>0.571997</td>\n",
       "      <td>0.630106</td>\n",
       "      <td>0.714430</td>\n",
       "      <td>0.675026</td>\n",
       "      <td>0.665222</td>\n",
       "      <td>0.719204</td>\n",
       "      <td>0.826163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242615e-10</td>\n",
       "      <td>2.971604e-10</td>\n",
       "      <td>2.766176e-10</td>\n",
       "      <td>2.603836e-10</td>\n",
       "      <td>2.475797e-10</td>\n",
       "      <td>2.377858e-10</td>\n",
       "      <td>2.303247e-10</td>\n",
       "      <td>2.252069e-10</td>\n",
       "      <td>2.220143e-10</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095527</td>\n",
       "      <td>0.703987</td>\n",
       "      <td>0.686745</td>\n",
       "      <td>0.652019</td>\n",
       "      <td>0.708184</td>\n",
       "      <td>0.785110</td>\n",
       "      <td>0.705763</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.727593</td>\n",
       "      <td>0.830990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.247757e-04</td>\n",
       "      <td>1.341399e-04</td>\n",
       "      <td>1.214583e-04</td>\n",
       "      <td>1.263136e-04</td>\n",
       "      <td>1.228761e-04</td>\n",
       "      <td>1.222476e-04</td>\n",
       "      <td>1.265383e-04</td>\n",
       "      <td>1.189884e-04</td>\n",
       "      <td>1.167818e-04</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059451</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.640867</td>\n",
       "      <td>0.584111</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.634756</td>\n",
       "      <td>0.718932</td>\n",
       "      <td>0.701798</td>\n",
       "      <td>0.665793</td>\n",
       "      <td>0.731998</td>\n",
       "      <td>...</td>\n",
       "      <td>1.885746e-10</td>\n",
       "      <td>1.724273e-10</td>\n",
       "      <td>1.642871e-10</td>\n",
       "      <td>1.507513e-10</td>\n",
       "      <td>1.506967e-10</td>\n",
       "      <td>1.413461e-10</td>\n",
       "      <td>1.223686e-10</td>\n",
       "      <td>1.028102e-10</td>\n",
       "      <td>9.267614e-11</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059764</td>\n",
       "      <td>0.452337</td>\n",
       "      <td>0.392475</td>\n",
       "      <td>0.459169</td>\n",
       "      <td>0.471747</td>\n",
       "      <td>0.485209</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.797795</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.943509e-08</td>\n",
       "      <td>3.484132e-08</td>\n",
       "      <td>3.144174e-08</td>\n",
       "      <td>2.883970e-08</td>\n",
       "      <td>2.684491e-08</td>\n",
       "      <td>2.534668e-08</td>\n",
       "      <td>2.423224e-08</td>\n",
       "      <td>2.347231e-08</td>\n",
       "      <td>2.300906e-08</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084948</td>\n",
       "      <td>0.507884</td>\n",
       "      <td>0.453309</td>\n",
       "      <td>0.514883</td>\n",
       "      <td>0.527360</td>\n",
       "      <td>0.533189</td>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.695444</td>\n",
       "      <td>0.800741</td>\n",
       "      <td>0.737847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433621e-04</td>\n",
       "      <td>1.483603e-04</td>\n",
       "      <td>1.489699e-04</td>\n",
       "      <td>1.448154e-04</td>\n",
       "      <td>1.439977e-04</td>\n",
       "      <td>1.399541e-04</td>\n",
       "      <td>1.476906e-04</td>\n",
       "      <td>1.396021e-04</td>\n",
       "      <td>1.398984e-04</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.053580  0.637844  0.606111  0.571997  0.630106  0.714430  0.675026   \n",
       "1  0.095527  0.703987  0.686745  0.652019  0.708184  0.785110  0.705763   \n",
       "2  0.059451  0.583235  0.640867  0.584111  0.567250  0.634756  0.718932   \n",
       "3  0.059764  0.452337  0.392475  0.459169  0.471747  0.485209  0.507530   \n",
       "4  0.084948  0.507884  0.453309  0.514883  0.527360  0.533189  0.539241   \n",
       "\n",
       "          7         8         9  ...           153           154  \\\n",
       "0  0.665222  0.719204  0.826163  ...  3.242615e-10  2.971604e-10   \n",
       "1  0.680851  0.727593  0.830990  ...  1.247757e-04  1.341399e-04   \n",
       "2  0.701798  0.665793  0.731998  ...  1.885746e-10  1.724273e-10   \n",
       "3  0.684371  0.797795  0.724068  ...  3.943509e-08  3.484132e-08   \n",
       "4  0.695444  0.800741  0.737847  ...  1.433621e-04  1.483603e-04   \n",
       "\n",
       "            155           156           157           158           159  \\\n",
       "0  2.766176e-10  2.603836e-10  2.475797e-10  2.377858e-10  2.303247e-10   \n",
       "1  1.214583e-04  1.263136e-04  1.228761e-04  1.222476e-04  1.265383e-04   \n",
       "2  1.642871e-10  1.507513e-10  1.506967e-10  1.413461e-10  1.223686e-10   \n",
       "3  3.144174e-08  2.883970e-08  2.684491e-08  2.534668e-08  2.423224e-08   \n",
       "4  1.489699e-04  1.448154e-04  1.439977e-04  1.399541e-04  1.476906e-04   \n",
       "\n",
       "            160           161   labels  \n",
       "0  2.252069e-10  2.220143e-10     fear  \n",
       "1  1.189884e-04  1.167818e-04     fear  \n",
       "2  1.028102e-10  9.267614e-11     fear  \n",
       "3  2.347231e-08  2.300906e-08  disgust  \n",
       "4  1.396021e-04  1.398984e-04  disgust  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21027, 162), (21027, 8), (14019, 162), (14019, 8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, shuffle=True, test_size=0.4)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21027, 162), (21027, 8), (14019, 162), (14019, 8))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21027, 162, 1), (21027, 8), (14019, 162, 1), (14019, 8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 22:55:38.520930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-21 22:55:38.520944: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 162, 256)          1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 81, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 81, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 41, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 21, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 11, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 704)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                22560     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557,288\n",
      "Trainable params: 557,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 22:55:39.713641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-21 22:55:39.713777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-21 22:55:39.713821: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-21 22:55:39.713852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-21 22:55:39.715867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-21 22:55:39.715901: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-21 22:55:39.715999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-21 22:55:39.716008: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-21 22:55:39.716247: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=8, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 1.7632 - accuracy: 0.3052 - val_loss: 1.5644 - val_accuracy: 0.3761 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.5286 - accuracy: 0.3841 - val_loss: 1.4040 - val_accuracy: 0.4488 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.4199 - accuracy: 0.4223 - val_loss: 1.3273 - val_accuracy: 0.4656 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.3661 - accuracy: 0.4521 - val_loss: 1.2967 - val_accuracy: 0.4805 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.3149 - accuracy: 0.4709 - val_loss: 1.2594 - val_accuracy: 0.4965 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.2784 - accuracy: 0.4860 - val_loss: 1.2162 - val_accuracy: 0.5059 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.2545 - accuracy: 0.4946 - val_loss: 1.2009 - val_accuracy: 0.5236 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.2301 - accuracy: 0.5129 - val_loss: 1.1794 - val_accuracy: 0.5266 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.2019 - accuracy: 0.5228 - val_loss: 1.1885 - val_accuracy: 0.5276 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.1869 - accuracy: 0.5250 - val_loss: 1.1684 - val_accuracy: 0.5301 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.1706 - accuracy: 0.5336 - val_loss: 1.1725 - val_accuracy: 0.5294 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 1.1541 - accuracy: 0.5394 - val_loss: 1.1604 - val_accuracy: 0.5348 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.1396 - accuracy: 0.5457 - val_loss: 1.1524 - val_accuracy: 0.5401 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.1281 - accuracy: 0.5531 - val_loss: 1.1205 - val_accuracy: 0.5505 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.1087 - accuracy: 0.5608 - val_loss: 1.1174 - val_accuracy: 0.5536 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.0999 - accuracy: 0.5655 - val_loss: 1.1174 - val_accuracy: 0.5521 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.0916 - accuracy: 0.5697 - val_loss: 1.1373 - val_accuracy: 0.5475 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.0660 - accuracy: 0.5772 - val_loss: 1.1237 - val_accuracy: 0.5551 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 15s 44ms/step - loss: 1.0544 - accuracy: 0.5842 - val_loss: 1.1143 - val_accuracy: 0.5565 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.0437 - accuracy: 0.5885 - val_loss: 1.1247 - val_accuracy: 0.5590 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.0432 - accuracy: 0.5859 - val_loss: 1.1146 - val_accuracy: 0.5592 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 1.0140 - accuracy: 0.5989 - val_loss: 1.1228 - val_accuracy: 0.5616 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 1.0178 - accuracy: 0.5965 - val_loss: 1.0986 - val_accuracy: 0.5649 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.9927 - accuracy: 0.6063 - val_loss: 1.0863 - val_accuracy: 0.5772 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.9902 - accuracy: 0.6041 - val_loss: 1.1353 - val_accuracy: 0.5611 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.9726 - accuracy: 0.6146 - val_loss: 1.0879 - val_accuracy: 0.5702 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.9680 - accuracy: 0.6179 - val_loss: 1.1060 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.9526 - accuracy: 0.6282 - val_loss: 1.1233 - val_accuracy: 0.5627 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.9366 - accuracy: 0.6293 - val_loss: 1.1105 - val_accuracy: 0.5681 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.9345 - accuracy: 0.6316 - val_loss: 1.1065 - val_accuracy: 0.5706 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.9275 - accuracy: 0.6365 - val_loss: 1.0999 - val_accuracy: 0.5779 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.9119 - accuracy: 0.6391 - val_loss: 1.1221 - val_accuracy: 0.5706 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.8954 - accuracy: 0.6464 - val_loss: 1.1179 - val_accuracy: 0.5843 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.8934 - accuracy: 0.6472 - val_loss: 1.1288 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.8733 - accuracy: 0.6542 - val_loss: 1.1365 - val_accuracy: 0.5723 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.8603 - accuracy: 0.6584 - val_loss: 1.1281 - val_accuracy: 0.5779 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.8673 - accuracy: 0.6606 - val_loss: 1.1420 - val_accuracy: 0.5802 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.8538 - accuracy: 0.6591 - val_loss: 1.1435 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.8409 - accuracy: 0.6664 - val_loss: 1.1402 - val_accuracy: 0.5782 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.8315 - accuracy: 0.6702 - val_loss: 1.1452 - val_accuracy: 0.5839 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.8356 - accuracy: 0.6716 - val_loss: 1.1722 - val_accuracy: 0.5781 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.8113 - accuracy: 0.6797 - val_loss: 1.1672 - val_accuracy: 0.5764 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.8024 - accuracy: 0.6866 - val_loss: 1.1537 - val_accuracy: 0.5799 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.8013 - accuracy: 0.6866 - val_loss: 1.1935 - val_accuracy: 0.5829 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.7834 - accuracy: 0.6923 - val_loss: 1.1799 - val_accuracy: 0.5773 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.7950 - accuracy: 0.6884 - val_loss: 1.1866 - val_accuracy: 0.5722 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.7732 - accuracy: 0.6959 - val_loss: 1.2058 - val_accuracy: 0.5815 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 14s 44ms/step - loss: 0.7603 - accuracy: 0.7004 - val_loss: 1.2487 - val_accuracy: 0.5858 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.7664 - accuracy: 0.6982 - val_loss: 1.1821 - val_accuracy: 0.5773 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.7408 - accuracy: 0.7080 - val_loss: 1.2354 - val_accuracy: 0.5767 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_test \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(get_features(\u001b[39m'\u001b[39m\u001b[39mCREMA-D/AudioWAV/1001_DFA_ANG_XX.wav\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      2\u001b[0m y_pred \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minverse_transform(pred_test)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(pred_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(get_features('CREMA-D/AudioWAV/1001_DFA_ANG_XX.wav'))\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "print(pred_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.60230978],\n",
       "        [ 1.06432152],\n",
       "        [ 0.96664612],\n",
       "        ...,\n",
       "        [ 0.11435008],\n",
       "        [ 0.09932767],\n",
       "        [ 0.13590263]],\n",
       "\n",
       "       [[ 1.51294131],\n",
       "        [ 0.53812178],\n",
       "        [ 0.37106885],\n",
       "        ...,\n",
       "        [ 9.42465293],\n",
       "        [ 8.75705927],\n",
       "        [ 9.19634411]],\n",
       "\n",
       "       [[ 2.10282279],\n",
       "        [ 1.49680979],\n",
       "        [ 1.25626752],\n",
       "        ...,\n",
       "        [ 0.30125337],\n",
       "        [ 0.28569037],\n",
       "        [ 0.26885255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.43730567],\n",
       "        [-0.25402187],\n",
       "        [ 0.0659814 ],\n",
       "        ...,\n",
       "        [-0.20552607],\n",
       "        [-0.19876009],\n",
       "        [-0.19784518]],\n",
       "\n",
       "       [[ 0.10441508],\n",
       "        [-0.83781867],\n",
       "        [-0.55856562],\n",
       "        ...,\n",
       "        [-0.20551179],\n",
       "        [-0.19875267],\n",
       "        [-0.19784046]],\n",
       "\n",
       "       [[ 0.85382609],\n",
       "        [-0.39001328],\n",
       "        [ 0.19314748],\n",
       "        ...,\n",
       "        [-0.20469089],\n",
       "        [-0.19867008],\n",
       "        [-0.19784537]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (112152) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPredicted Labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mActual Labels\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mPredicted Labels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m----> 3\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mActual Labels\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3978\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3975\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3976\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3977\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3978\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4172\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4163\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4170\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4171\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4172\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4174\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4175\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4176\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4177\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4178\u001b[0m     ):\n\u001b[1;32m   4179\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4180\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4909\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4911\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4912\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4913\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (112152) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['val_accuracy']\n",
    "epochs = range(0,50)\n",
    "plt.plot(epochs, acc, 'b', label = 'Training Accuracy')\n",
    "plt.title('ASA Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14019, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 4\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize \u001b[39m=\u001b[39m (\u001b[39m12\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[1;32m      6\u001b[0m cm \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(cm , index \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m encoder\u001b[39m.\u001b[39mcategories_] , columns \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m encoder\u001b[39m.\u001b[39mcategories_])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[1;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m     \u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14019, 3]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83757/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_83757/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m wf\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     37\u001b[0m audioFile \u001b[39m=\u001b[39m get_features(WAVE_OUTPUT_FILENAME)\n\u001b[0;32m---> 38\u001b[0m sent \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(audioFile)\n\u001b[1;32m     39\u001b[0m sentiment \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minverse_transform(sent)\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(sentiment)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "while True:\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = \"AudioOutput.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"* done recording\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    audioFile = get_features(WAVE_OUTPUT_FILENAME)\n",
    "    sent = model.predict(audioFile)\n",
    "    sentiment = encoder.inverse_transform(sent)\n",
    "    print(sentiment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['neutral']\n",
      " ['fear']\n",
      " ['neutral']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75666/2561136619.py:9: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/tmp/ipykernel_75666/2561136619.py:16: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n"
     ]
    }
   ],
   "source": [
    "thing = get_features('archive/tess toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_pleasant_surprised/YAF_back_ps.wav')\n",
    "breh = model.predict(thing)\n",
    "print(encoder.inverse_transform(breh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "pred_test = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "\n",
    "y_test = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "\"\"\"\n",
    "3=angry\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema_df['Emotions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
